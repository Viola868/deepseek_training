Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/bin/ds", line 3, in <module>
    from deepspeed.launcher.runner import main
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/__init__.py", line 25, in <module>
    from . import ops
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/ops/__init__.py", line 6, in <module>
    from . import adam
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/ops/adam/__init__.py", line 6, in <module>
    from .cpu_adam import DeepSpeedCPUAdam
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/ops/adam/cpu_adam.py", line 8, in <module>
    from deepspeed.utils import logger
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/__init__.py", line 10, in <module>
    from .groups import *
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/groups.py", line 28, in <module>
    from deepspeed import comm as dist
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/comm/__init__.py", line 7, in <module>
    from .comm import *
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/comm/comm.py", line 30, in <module>
    from deepspeed.accelerator import get_accelerator
ModuleNotFoundError: No module named 'deepspeed.accelerator'
Traceback (most recent call last):
  File "training_swanlab.py", line 3, in <module>
    import swanlab  # SwanLab 实验跟踪
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/__init__.py", line 9, in <module>
    SwanLabEnv.set_default()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/env.py", line 117, in set_default
    path = os.path.join(get_save_dir(), ".netrc")
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/env.py", line 111, in get_save_dir
    os.mkdir(folder)
FileExistsError: [Errno 17] File exists: '/share/home/zhangshanqi/.swanlab'
Traceback (most recent call last):
  File "training_swanlab.py", line 3, in <module>
    import swanlab  # SwanLab 实验跟踪
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/__init__.py", line 9, in <module>
    SwanLabEnv.set_default()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/env.py", line 117, in set_default
    path = os.path.join(get_save_dir(), ".netrc")
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/env.py", line 111, in get_save_dir
    os.mkdir(folder)
FileExistsError: [Errno 17] File exists: '/share/home/zhangshanqi/.swanlab'
Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
    http = get_http()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
    http = get_http()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
    raise ValueError("http object is not initialized")
ValueError: http object is not initialized

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "training_swanlab.py", line 157, in <module>
    raise ValueError("http object is not initialized")
ValueError: http object is not initialized

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "training_swanlab.py", line 157, in <module>
    main()
  File "training_swanlab.py", line 25, in main
    swanlab.init('deepseek_train')
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
    main()
  File "training_swanlab.py", line 25, in main
    swanlab.init('deepseek_train')
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
    operator.on_init(project, workspace, logdir=logdir),
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
    operator.on_init(project, workspace, logdir=logdir),
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
    return self.__run_all(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
    return self.__run_all(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
    http = create_http(self.create_login_info())
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info
    http = create_http(self.create_login_info())
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info
    return terminal_login(key, save)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
    return terminal_login(key, save)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
    return code_login(api_key, save_key)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
    login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading
    return code_login(api_key, save_key)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
    login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading
    raise error
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
    result = func(*args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
    resp = login_request(api_key, api_host, timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
    resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)    
raise error  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
    result = func(*args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
    resp = login_request(api_key, api_host, timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
    resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
    return request("post", url, data=data, json=json, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
    return session.request(method=method, url=url, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
    resp = self.send(prep, **send_kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
    requests.exceptionsraise ConnectionError(e, request=request).
ConnectionErrorrequests.exceptions: .HTTPSConnectionPool(host='api.swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2b0d2b1da8b0>: Failed to establish a new connection: [Errno -2] Name or service not known'))ConnectionError
: HTTPSConnectionPool(host='api.swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2b314d901970>: Failed to establish a new connection: [Errno -2] Name or service not known'))
Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
    http = get_http()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
    http = get_http()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
    raise ValueError("http object is not initialized")
ValueError    : raise ValueError("http object is not initialized")http object is not initialized


During handling of the above exception, another exception occurred:

ValueErrorTraceback (most recent call last):
:   File "training_swanlab.py", line 157, in <module>
http object is not initialized

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "training_swanlab.py", line 157, in <module>
        main()main()

  File "training_swanlab.py", line 25, in main
  File "training_swanlab.py", line 25, in main
    swanlab.init('deepseek_train')
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
swanlab.init('deepseek_train')
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
        operator.on_init(project, workspace, logdir=logdir),operator.on_init(project, workspace, logdir=logdir),

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
    return self.__run_all(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
    return self.__run_all(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
    http = create_http(self.create_login_info())
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info
    http = create_http(self.create_login_info())    
return terminal_login(key, save)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
    return terminal_login(key, save)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
    return code_login(api_key, save_key)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
    return code_login(api_key, save_key)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
    login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading
    login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading
    raise error    
raise error  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
    result = func(*args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
    result = func(*args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
    resp = login_request(api_key, api_host, timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
    resp = login_request(api_key, api_host, timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
    resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
    resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
        return request("post", url, data=data, json=json, **kwargs)return request("post", url, data=data, json=json, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
        return session.request(method=method, url=url, **kwargs)return session.request(method=method, url=url, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
resp = self.send(prep, **send_kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
    r = adapter.send(request, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='api.swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2aebb5f13a00>: Failed to establish a new connection: [Errno -2] Name or service not known'))
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='api.swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2acc53d77970>: Failed to establish a new connection: [Errno -2] Name or service not known'))
Traceback (most recent call last):
Traceback (most recent call last):
  File "training_swanlab.py", line 17, in <module>
  File "training_swanlab.py", line 17, in <module>
    if not SWANLAB_HOST or not SWANLAB_API_KEY:
    if not SWANLAB_HOST or not SWANLAB_API_KEY:NameError
: name 'SWANLAB_HOST' is not definedNameError
: name 'SWANLAB_HOST' is not defined
Traceback (most recent call last):
Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
        http = get_http()http = get_http()

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
        raise ValueError("http object is not initialized")raise ValueError("http object is not initialized")

ValueErrorValueError: : http object is not initializedhttp object is not initialized


During handling of the above exception, another exception occurred:


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
Traceback (most recent call last):
  File "training_swanlab.py", line 157, in <module>
  File "training_swanlab.py", line 157, in <module>
    main()
  File "training_swanlab.py", line 25, in main
    main()
  File "training_swanlab.py", line 25, in main
    swanlab.init('deepseek_train')
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
    swanlab.init('deepseek_train')
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
    operator.on_init(project, workspace, logdir=logdir),
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
    operator.on_init(project, workspace, logdir=logdir),
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
        return self.__run_all(return self.__run_all(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}    
return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}    
return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
    http = create_http(self.create_login_info())    
http = create_http(self.create_login_info())  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info
    return terminal_login(key, save)    
return terminal_login(key, save)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
        return code_login(api_key, save_key)return code_login(api_key, save_key)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
        login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading
    raise error
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
raise error
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
    result = func(*args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
    result = func(*args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
    resp = login_request(api_key, api_host, timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
    resp = login_request(api_key, api_host, timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
    resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
    resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
        return request("post", url, data=data, json=json, **kwargs)return request("post", url, data=data, json=json, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
        return session.request(method=method, url=url, **kwargs)return session.request(method=method, url=url, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
        resp = self.send(prep, **send_kwargs)resp = self.send(prep, **send_kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)    
r = adapter.send(request, **kwargs)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions    .raise ConnectionError(e, request=request)ConnectionError
: requests.exceptionsHTTPSConnectionPool(host='api.swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2aefabf61940>: Failed to establish a new connection: [Errno -2] Name or service not known')).
ConnectionError: HTTPSConnectionPool(host='api.swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2b0d93d49940>: Failed to establish a new connection: [Errno -2] Name or service not known'))
Traceback (most recent call last):
Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
        http = get_http()http = get_http()

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
        raise ValueError("http object is not initialized")raise ValueError("http object is not initialized")

ValueErrorValueError: : http object is not initializedhttp object is not initialized


During handling of the above exception, another exception occurred:


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
Traceback (most recent call last):
  File "training_swanlab.py", line 163, in <module>
  File "training_swanlab.py", line 163, in <module>
        main()main()

  File "training_swanlab.py", line 25, in main
  File "training_swanlab.py", line 25, in main
    swanlab.init(    
swanlab.init(  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
        operator.on_init(project, workspace, logdir=logdir),operator.on_init(project, workspace, logdir=logdir),

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
        return self.__run_all(return self.__run_all(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
        return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}    
return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
    http = create_http(self.create_login_info())    
http = create_http(self.create_login_info())  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info
    return terminal_login(key, save)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
return terminal_login(key, save)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
        return code_login(api_key, save_key)
return code_login(api_key, save_key)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
    login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)    
login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading
        raise errorraise error

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
    result = func(*args)    
result = func(*args)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
    resp = login_request(api_key, api_host, timeout)    
resp = login_request(api_key, api_host, timeout)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
    resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
        return request("post", url, data=data, json=json, **kwargs)return request("post", url, data=data, json=json, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
        return session.request(method=method, url=url, **kwargs)return session.request(method=method, url=url, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
        resp = self.send(prep, **send_kwargs)resp = self.send(prep, **send_kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
        r = adapter.send(request, **kwargs)r = adapter.send(request, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
        raise ConnectionError(e, request=request)raise ConnectionError(e, request=request)

requests.exceptionsrequests.exceptions..ConnectionErrorConnectionError: : HTTPSConnectionPool(host='api.swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2b9fc7461940>: Failed to establish a new connection: [Errno -2] Name or service not known'))HTTPSConnectionPool(host='api.swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2b3cbe80e940>: Failed to establish a new connection: [Errno -2] Name or service not known'))

Traceback (most recent call last):
Traceback (most recent call last):
  File "training_swanlab.py", line 3, in <module>
  File "training_swanlab.py", line 3, in <module>
        HOST = os.environ.get('https://swanlab.cn')    # 👉 应该是 “https://swanlab.cn”HOST = os.environ.get('https://swanlab.cn')    # 👉 应该是 “https://swanlab.cn”

NameErrorNameError: : name 'os' is not definedname 'os' is not defined

Traceback (most recent call last):
Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
        http = get_http()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
http = get_http()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
        raise ValueError("http object is not initialized")raise ValueError("http object is not initialized")

ValueErrorValueError: : http object is not initializedhttp object is not initialized


During handling of the above exception, another exception occurred:


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
Traceback (most recent call last):
  File "training_swanlab.py", line 165, in <module>
  File "training_swanlab.py", line 165, in <module>
        main()main()

  File "training_swanlab.py", line 27, in main
  File "training_swanlab.py", line 27, in main
        swanlab.init(swanlab.init(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
        operator.on_init(project, workspace, logdir=logdir),operator.on_init(project, workspace, logdir=logdir),

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
        return self.__run_all(return self.__run_all(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
        return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>
        return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
        http = create_http(self.create_login_info())http = create_http(self.create_login_info())

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info
        return terminal_login(key, save)return terminal_login(key, save)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
        return code_login(api_key, save_key)return code_login(api_key, save_key)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
    login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)    
login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading
        raise errorraise error

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
        result = func(*args)result = func(*args)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
        resp = login_request(api_key, api_host, timeout)resp = login_request(api_key, api_host, timeout)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
        resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
        return request("post", url, data=data, json=json, **kwargs)return request("post", url, data=data, json=json, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)    
return session.request(method=method, url=url, **kwargs)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
        resp = self.send(prep, **send_kwargs)resp = self.send(prep, **send_kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
        r = adapter.send(request, **kwargs)r = adapter.send(request, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
        raise ConnectionError(e, request=request)raise ConnectionError(e, request=request)

requests.exceptionsrequests.exceptions..ConnectionErrorConnectionError: : HTTPSConnectionPool(host='api.swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2b40427da8e0>: Failed to establish a new connection: [Errno -2] Name or service not known'))HTTPSConnectionPool(host='api.swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2b57d2b82a30>: Failed to establish a new connection: [Errno -2] Name or service not known'))

Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
    http = get_http()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
    raise ValueError("http object is not initialized")
ValueError: http object is not initialized

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "training_swanlab.py", line 165, in <module>
    main()
  File "training_swanlab.py", line 27, in main
    swanlab.init(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
    operator.on_init(project, workspace, logdir=logdir),
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
    return self.__run_all(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
    http = create_http(self.create_login_info())
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info
    return terminal_login(key, save)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
    return code_login(api_key, save_key)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
    login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading
    raise error
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
    result = func(*args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
    resp = login_request(api_key, api_host, timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
    resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='api.swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2ab0c1a07610>: Failed to establish a new connection: [Errno -2] Name or service not known'))
Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
    http = get_http()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
    raise ValueError("http object is not initialized")
ValueError: http object is not initialized

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "training_swanlab.py", line 165, in <module>
    main()
  File "training_swanlab.py", line 27, in main
    swanlab.init(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
    operator.on_init(project, workspace, logdir=logdir),
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
    return self.__run_all(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
    http = create_http(self.create_login_info())
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info
    return terminal_login(key, save)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
    return code_login(api_key, save_key)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
    login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading
    raise error
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
    result = func(*args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
    resp = login_request(api_key, api_host, timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
    resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='api.swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2acf1f6b56d0>: Failed to establish a new connection: [Errno -2] Name or service not known'))
Traceback (most recent call last):
Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
        http = get_http()http = get_http()

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
        raise ValueError("http object is not initialized")raise ValueError("http object is not initialized")

ValueErrorValueError: : http object is not initializedhttp object is not initialized


During handling of the above exception, another exception occurred:


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
Traceback (most recent call last):
  File "training_swanlab.py", line 165, in <module>
  File "training_swanlab.py", line 165, in <module>
        main()main()

  File "training_swanlab.py", line 27, in main
  File "training_swanlab.py", line 27, in main
        swanlab.init(swanlab.init(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
        operator.on_init(project, workspace, logdir=logdir),operator.on_init(project, workspace, logdir=logdir),

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
        return self.__run_all(return self.__run_all(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
        return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>
        return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
    http = create_http(self.create_login_info())
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info
    http = create_http(self.create_login_info())    
return terminal_login(key, save)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
    return terminal_login(key, save)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
        return code_login(api_key, save_key)return code_login(api_key, save_key)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
    login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)    
login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading
        raise errorraise error

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
    result = func(*args)    
result = func(*args)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
    resp = login_request(api_key, api_host, timeout)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
resp = login_request(api_key, api_host, timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
    resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
        return request("post", url, data=data, json=json, **kwargs)return request("post", url, data=data, json=json, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
        return session.request(method=method, url=url, **kwargs)return session.request(method=method, url=url, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)    
resp = self.send(prep, **send_kwargs)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
r = adapter.send(request, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
    requests.exceptionsraise ConnectionError(e, request=request).
ConnectionErrorrequests.exceptions: .HTTPSConnectionPool(host='api.swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2b8d769bd640>: Failed to establish a new connection: [Errno -2] Name or service not known'))ConnectionError
: HTTPSConnectionPool(host='api.swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2b30d8742610>: Failed to establish a new connection: [Errno -2] Name or service not known'))
Traceback (most recent call last):
Traceback (most recent call last):
  File "training_swanlab.py", line 165, in <module>
  File "training_swanlab.py", line 165, in <module>
        main()main()

  File "training_swanlab.py", line 29, in main
  File "training_swanlab.py", line 29, in main
        host=HOST,host=HOST,

NameErrorNameError: : name 'HOST' is not definedname 'HOST' is not defined

Traceback (most recent call last):
Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
        http = get_http()http = get_http()

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
        raise ValueError("http object is not initialized")raise ValueError("http object is not initialized")

ValueErrorValueError: : http object is not initializedhttp object is not initialized


During handling of the above exception, another exception occurred:


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
Traceback (most recent call last):
  File "training_swanlab.py", line 165, in <module>
  File "training_swanlab.py", line 165, in <module>
        main()main()

  File "training_swanlab.py", line 27, in main
  File "training_swanlab.py", line 27, in main
    swanlab.init(    
swanlab.init(  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
    operator.on_init(project, workspace, logdir=logdir),    
operator.on_init(project, workspace, logdir=logdir),  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
        return self.__run_all(return self.__run_all(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
        return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>
        return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
    http = create_http(self.create_login_info())
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info
    http = create_http(self.create_login_info())    
return terminal_login(key, save)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
    return terminal_login(key, save)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
        return code_login(api_key, save_key)return code_login(api_key, save_key)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
    login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)    
login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading
        raise errorraise error

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
        result = func(*args)result = func(*args)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
        resp = login_request(api_key, api_host, timeout)resp = login_request(api_key, api_host, timeout)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
        resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)    
return request("post", url, data=data, json=json, **kwargs)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
return session.request(method=method, url=url, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
        resp = self.send(prep, **send_kwargs)resp = self.send(prep, **send_kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)    
r = adapter.send(request, **kwargs)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
    requests.exceptionsraise ConnectionError(e, request=request).
ConnectionErrorrequests.exceptions: .HTTPSConnectionPool(host='api.swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2b899a1fd670>: Failed to establish a new connection: [Errno -2] Name or service not known'))ConnectionError
: HTTPSConnectionPool(host='api.swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2ab08b1e45e0>: Failed to establish a new connection: [Errno -2] Name or service not known'))
Traceback (most recent call last):
Traceback (most recent call last):
  File "training_swanlab.py", line 167, in <module>
  File "training_swanlab.py", line 167, in <module>
        main()main()

  File "training_swanlab.py", line 31, in main
  File "training_swanlab.py", line 31, in main
        host=HOST,host=HOST,

NameErrorNameError: : name 'HOST' is not definedname 'HOST' is not defined

Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
    http = get_http()
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
http = get_http()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
        raise ValueError("http object is not initialized")raise ValueError("http object is not initialized")

ValueErrorValueError: : http object is not initializedhttp object is not initialized


During handling of the above exception, another exception occurred:


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
Traceback (most recent call last):
  File "training_swanlab.py", line 167, in <module>
  File "training_swanlab.py", line 167, in <module>
    main()
      File "training_swanlab.py", line 29, in main
main()
  File "training_swanlab.py", line 29, in main
    swanlab.init(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
    swanlab.init(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
    operator.on_init(project, workspace, logdir=logdir),
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
operator.on_init(project, workspace, logdir=logdir),
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
        return self.__run_all(return self.__run_all(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
        return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>
        return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
    http = create_http(self.create_login_info())
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info
http = create_http(self.create_login_info())
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info
    return terminal_login(key, save)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
    return terminal_login(key, save)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
    return code_login(api_key, save_key)    
return code_login(api_key, save_key)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
    login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading
    login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading
    raise error    
raise error  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
    result = func(*args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
    result = func(*args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
    resp = login_request(api_key, api_host, timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
    resp = login_request(api_key, api_host, timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
    resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
    resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
        return request("post", url, data=data, json=json, **kwargs)return request("post", url, data=data, json=json, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
        return session.request(method=method, url=url, **kwargs)return session.request(method=method, url=url, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
        resp = self.send(prep, **send_kwargs)resp = self.send(prep, **send_kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
        r = adapter.send(request, **kwargs)r = adapter.send(request, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)    
raise ConnectionError(e, request=request)
requests.exceptionsrequests.exceptions..ConnectionErrorConnectionError: : HTTPSConnectionPool(host='api.swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2ab3855f25b0>: Failed to establish a new connection: [Errno -2] Name or service not known'))HTTPSConnectionPool(host='api.swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2b4b27688580>: Failed to establish a new connection: [Errno -2] Name or service not known'))

Traceback (most recent call last):
Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
        http = get_http()http = get_http()

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
        raise ValueError("http object is not initialized")raise ValueError("http object is not initialized")

ValueErrorValueError: : http object is not initializedhttp object is not initialized


During handling of the above exception, another exception occurred:


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
Traceback (most recent call last):
  File "training_swanlab.py", line 166, in <module>
  File "training_swanlab.py", line 166, in <module>
        main()main()

  File "training_swanlab.py", line 27, in main
  File "training_swanlab.py", line 27, in main
        swanlab.init('deepseek_train')swanlab.init('deepseek_train')

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
        operator.on_init(project, workspace, logdir=logdir),operator.on_init(project, workspace, logdir=logdir),

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
    return self.__run_all(    
return self.__run_all(  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>
return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
    http = create_http(self.create_login_info())
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info
http = create_http(self.create_login_info())
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info
    return terminal_login(key, save)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
return terminal_login(key, save)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
    return code_login(api_key, save_key)    
return code_login(api_key, save_key)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
    login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading
login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading
        raise errorraise error

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
        result = func(*args)result = func(*args)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
        resp = login_request(api_key, api_host, timeout)resp = login_request(api_key, api_host, timeout)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
    resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)    
resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
        return request("post", url, data=data, json=json, **kwargs)return request("post", url, data=data, json=json, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
        return session.request(method=method, url=url, **kwargs)return session.request(method=method, url=url, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
        resp = self.send(prep, **send_kwargs)resp = self.send(prep, **send_kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
        r = adapter.send(request, **kwargs)r = adapter.send(request, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)    
raise ConnectionError(e, request=request)requests.exceptions
.requests.exceptionsConnectionError.: ConnectionErrorHTTPSConnectionPool(host='api.swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2af1160a2580>: Failed to establish a new connection: [Errno -2] Name or service not known'))
: HTTPSConnectionPool(host='api.swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2aad2e6d2640>: Failed to establish a new connection: [Errno -2] Name or service not known'))
Traceback (most recent call last):
Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
    http = get_http()    
http = get_http()  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
        raise ValueError("http object is not initialized")raise ValueError("http object is not initialized")

ValueErrorValueError: : http object is not initializedhttp object is not initialized


During handling of the above exception, another exception occurred:


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
Traceback (most recent call last):
  File "training_swanlab.py", line 166, in <module>
  File "training_swanlab.py", line 166, in <module>
    main()
      File "training_swanlab.py", line 27, in main
main()
  File "training_swanlab.py", line 27, in main
    swanlab.init('deepseek_train')
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
    swanlab.init('deepseek_train')
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
    operator.on_init(project, workspace, logdir=logdir),
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
operator.on_init(project, workspace, logdir=logdir),
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
    return self.__run_all(    
return self.__run_all(  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
    http = create_http(self.create_login_info())
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info
    http = create_http(self.create_login_info())
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info
    return terminal_login(key, save)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
    return terminal_login(key, save)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
    return code_login(api_key, save_key)    
return code_login(api_key, save_key)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
    login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)    
login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading
    raise error    
raise error  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
    result = func(*args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
    result = func(*args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
    resp = login_request(api_key, api_host, timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
    resp = login_request(api_key, api_host, timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
    resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
    resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
    return request("post", url, data=data, json=json, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
    return session.request(method=method, url=url, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
resp = self.send(prep, **send_kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
    r = adapter.send(request, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
        raise ConnectionError(e, request=request)raise ConnectionError(e, request=request)

requests.exceptionsrequests.exceptions..ConnectionErrorConnectionError: : HTTPSConnectionPool(host='swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2b07ab960580>: Failed to establish a new connection: [Errno -2] Name or service not known'))HTTPSConnectionPool(host='swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2b9cafe85670>: Failed to establish a new connection: [Errno -2] Name or service not known'))

Traceback (most recent call last):
Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
        http = get_http()http = get_http()

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
        raise ValueError("http object is not initialized")raise ValueError("http object is not initialized")

ValueErrorValueError: : http object is not initializedhttp object is not initialized


During handling of the above exception, another exception occurred:


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
Traceback (most recent call last):
  File "training_swanlab.py", line 166, in <module>
  File "training_swanlab.py", line 166, in <module>
        main()main()

  File "training_swanlab.py", line 27, in main
  File "training_swanlab.py", line 27, in main
    swanlab.init('deepseek_train')    
swanlab.init('deepseek_train')  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
        operator.on_init(project, workspace, logdir=logdir),operator.on_init(project, workspace, logdir=logdir),

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
    return self.__run_all(    
return self.__run_all(  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>
return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
    http = create_http(self.create_login_info())
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info
http = create_http(self.create_login_info())
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info
    return terminal_login(key, save)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
return terminal_login(key, save)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
    return code_login(api_key, save_key)    
return code_login(api_key, save_key)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
    login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading
    login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading
    raise error
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
raise error
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
    result = func(*args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
    result = func(*args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
    resp = login_request(api_key, api_host, timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
    resp = login_request(api_key, api_host, timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
    resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
    resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
        return request("post", url, data=data, json=json, **kwargs)return request("post", url, data=data, json=json, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
        return session.request(method=method, url=url, **kwargs)return session.request(method=method, url=url, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
        resp = self.send(prep, **send_kwargs)resp = self.send(prep, **send_kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
        r = adapter.send(request, **kwargs)r = adapter.send(request, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
        raise ConnectionError(e, request=request)raise ConnectionError(e, request=request)

requests.exceptionsrequests.exceptions..ConnectionErrorConnectionError: : HTTPSConnectionPool(host='swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2ae1621936d0>: Failed to establish a new connection: [Errno -2] Name or service not known'))HTTPSConnectionPool(host='swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2adb5d96e6a0>: Failed to establish a new connection: [Errno -2] Name or service not known'))

Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
        http = get_http()http = get_http()

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
        raise ValueError("http object is not initialized")raise ValueError("http object is not initialized")

ValueErrorValueError: : http object is not initializedhttp object is not initialized


During handling of the above exception, another exception occurred:


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
Traceback (most recent call last):
  File "training_swanlab.py", line 166, in <module>
  File "training_swanlab.py", line 166, in <module>
    main()    
main()  File "training_swanlab.py", line 28, in main

  File "training_swanlab.py", line 28, in main
    swanlab.init(
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
swanlab.init(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
        operator.on_init(project, workspace, logdir=logdir),operator.on_init(project, workspace, logdir=logdir),

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
        return self.__run_all(return self.__run_all(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>
return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
    http = create_http(self.create_login_info())
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info
    http = create_http(self.create_login_info())
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info
    return terminal_login(key, save)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
    return terminal_login(key, save)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
        return code_login(api_key, save_key)return code_login(api_key, save_key)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
    login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)    
login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading
        raise errorraise error

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
        result = func(*args)result = func(*args)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
        resp = login_request(api_key, api_host, timeout)resp = login_request(api_key, api_host, timeout)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
        resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
        return request("post", url, data=data, json=json, **kwargs)return request("post", url, data=data, json=json, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
        return session.request(method=method, url=url, **kwargs)return session.request(method=method, url=url, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
resp = self.send(prep, **send_kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
r = adapter.send(request, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
        raise ConnectionError(e, request=request)raise ConnectionError(e, request=request)

requests.exceptionsrequests.exceptions..ConnectionErrorConnectionError: : HTTPSConnectionPool(host='swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2b16ea2ca6a0>: Failed to establish a new connection: [Errno -2] Name or service not known'))HTTPSConnectionPool(host='swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2b43cf862670>: Failed to establish a new connection: [Errno -2] Name or service not known'))

Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
    http = get_http()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
    http = get_http()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
    raise ValueError("http object is not initialized")
    ValueErrorraise ValueError("http object is not initialized"): 
http object is not initialized

During handling of the above exception, another exception occurred:

ValueErrorTraceback (most recent call last):
: http object is not initialized  File "training_swanlab.py", line 166, in <module>


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "training_swanlab.py", line 166, in <module>
        main()main()

  File "training_swanlab.py", line 28, in main
  File "training_swanlab.py", line 28, in main
        swanlab.init(swanlab.init(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
        operator.on_init(project, workspace, logdir=logdir),operator.on_init(project, workspace, logdir=logdir),

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
        return self.__run_all(return self.__run_all(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>
return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
    http = create_http(self.create_login_info())
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info
http = create_http(self.create_login_info())
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info
    return terminal_login(key, save)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
return terminal_login(key, save)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
        return code_login(api_key, save_key)return code_login(api_key, save_key)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
        login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading
        raise errorraise error

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
        result = func(*args)result = func(*args)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
        resp = login_request(api_key, api_host, timeout)
resp = login_request(api_key, api_host, timeout)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
    resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)    
resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
        return request("post", url, data=data, json=json, **kwargs)return request("post", url, data=data, json=json, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
        return session.request(method=method, url=url, **kwargs)return session.request(method=method, url=url, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)    
resp = self.send(prep, **send_kwargs)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
r = adapter.send(request, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
        raise ConnectionError(e, request=request)raise ConnectionError(e, request=request)

requests.exceptionsrequests.exceptions..ConnectionErrorConnectionError: : HTTPSConnectionPool(host='swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2b971754f730>: Failed to establish a new connection: [Errno -2] Name or service not known'))HTTPSConnectionPool(host='swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2ba16ba15730>: Failed to establish a new connection: [Errno -2] Name or service not known'))

Traceback (most recent call last):
Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
        http = get_http()http = get_http()

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
        raise ValueError("http object is not initialized")raise ValueError("http object is not initialized")

ValueErrorValueError: : http object is not initializedhttp object is not initialized


During handling of the above exception, another exception occurred:


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
Traceback (most recent call last):
  File "training_swanlab.py", line 167, in <module>
  File "training_swanlab.py", line 167, in <module>
        main()main()

  File "training_swanlab.py", line 28, in main
  File "training_swanlab.py", line 28, in main
        swanlab.init(swanlab.init(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
        operator.on_init(project, workspace, logdir=logdir),operator.on_init(project, workspace, logdir=logdir),

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
        return self.__run_all(return self.__run_all(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}    
return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
    http = create_http(self.create_login_info())
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info
http = create_http(self.create_login_info())
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info
    return terminal_login(key, save)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
return terminal_login(key, save)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
        return code_login(api_key, save_key)return code_login(api_key, save_key)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
    login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)    
login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading
    raise error    
raise error  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
    result = func(*args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
    result = func(*args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
    resp = login_request(api_key, api_host, timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
    resp = login_request(api_key, api_host, timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
    resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)    
return request("post", url, data=data, json=json, **kwargs)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
return session.request(method=method, url=url, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
        resp = self.send(prep, **send_kwargs)resp = self.send(prep, **send_kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
        r = adapter.send(request, **kwargs)r = adapter.send(request, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
        raise ConnectionError(e, request=request)raise ConnectionError(e, request=request)

requests.exceptionsrequests.exceptions..ConnectionErrorConnectionError: : HTTPSConnectionPool(host='swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2b58fa62a730>: Failed to establish a new connection: [Errno -2] Name or service not known'))HTTPSConnectionPool(host='swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2b0300d08760>: Failed to establish a new connection: [Errno -2] Name or service not known'))

  File "training_swanlab.py", line 31
    host='https://swanlab.cn',
    ^
  File "training_swanlab.py", line 31
SyntaxError    : host='https://swanlab.cn',
invalid syntax    
^
SyntaxError: invalid syntax
Traceback (most recent call last):
Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
        http = get_http()http = get_http()

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
        raise ValueError("http object is not initialized")raise ValueError("http object is not initialized")

ValueErrorValueError: : http object is not initializedhttp object is not initialized


During handling of the above exception, another exception occurred:


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
Traceback (most recent call last):
  File "training_swanlab.py", line 168, in <module>
  File "training_swanlab.py", line 168, in <module>
        main()main()

  File "training_swanlab.py", line 28, in main
  File "training_swanlab.py", line 28, in main
        swanlab.init(swanlab.init(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
    operator.on_init(project, workspace, logdir=logdir),    
operator.on_init(project, workspace, logdir=logdir),
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
        return self.__run_all(return self.__run_all(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}    
return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
    http = create_http(self.create_login_info())
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info
    http = create_http(self.create_login_info())
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info
    return terminal_login(key, save)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
    return terminal_login(key, save)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
        return code_login(api_key, save_key)return code_login(api_key, save_key)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
        login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading
        raise errorraise error

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
        result = func(*args)result = func(*args)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
        resp = login_request(api_key, api_host, timeout)resp = login_request(api_key, api_host, timeout)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
        resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
        return request("post", url, data=data, json=json, **kwargs)return request("post", url, data=data, json=json, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)    
return session.request(method=method, url=url, **kwargs)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
        resp = self.send(prep, **send_kwargs)resp = self.send(prep, **send_kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)    
r = adapter.send(request, **kwargs)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
        raise ConnectionError(e, request=request)raise ConnectionError(e, request=request)

requests.exceptionsrequests.exceptions..ConnectionErrorConnectionError: : HTTPSConnectionPool(host='swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2afde892f7f0>: Failed to establish a new connection: [Errno -2] Name or service not known'))HTTPSConnectionPool(host='swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2af27007c7c0>: Failed to establish a new connection: [Errno -2] Name or service not known'))

Traceback (most recent call last):
Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
        http = get_http()http = get_http()

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
        raise ValueError("http object is not initialized")raise ValueError("http object is not initialized")

ValueErrorValueError: : http object is not initializedhttp object is not initialized


During handling of the above exception, another exception occurred:


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
Traceback (most recent call last):
  File "training_swanlab.py", line 168, in <module>
  File "training_swanlab.py", line 168, in <module>
        main()main()

  File "training_swanlab.py", line 28, in main
  File "training_swanlab.py", line 28, in main
        swanlab.init(swanlab.init(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
    operator.on_init(project, workspace, logdir=logdir),
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
operator.on_init(project, workspace, logdir=logdir),
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
        return self.__run_all(return self.__run_all(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
        return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>
        return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
        http = create_http(self.create_login_info())http = create_http(self.create_login_info())

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info
        return terminal_login(key, save)return terminal_login(key, save)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
        return code_login(api_key, save_key)return code_login(api_key, save_key)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
        login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading
        raise errorraise error

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
    result = func(*args)    
result = func(*args)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
    resp = login_request(api_key, api_host, timeout)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
resp = login_request(api_key, api_host, timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
    resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
        return request("post", url, data=data, json=json, **kwargs)return request("post", url, data=data, json=json, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
    return session.request(method=method, url=url, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
        resp = self.send(prep, **send_kwargs)resp = self.send(prep, **send_kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
        r = adapter.send(request, **kwargs)r = adapter.send(request, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
        raise ConnectionError(e, request=request)raise ConnectionError(e, request=request)

requests.exceptionsrequests.exceptions..ConnectionErrorConnectionError: : HTTPSConnectionPool(host='swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2acd0d29a7c0>: Failed to establish a new connection: [Errno -2] Name or service not known'))HTTPSConnectionPool(host='swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2b5a50fb8760>: Failed to establish a new connection: [Errno -2] Name or service not known'))

Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
    http = get_http()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
    http = get_http()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
    raise ValueError("http object is not initialized")
ValueError: http object is not initialized

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
      File "training_swanlab.py", line 168, in <module>
raise ValueError("http object is not initialized")
ValueError: http object is not initialized

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "training_swanlab.py", line 168, in <module>
    main()
      File "training_swanlab.py", line 28, in main
main()
  File "training_swanlab.py", line 28, in main
    swanlab.init(
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
swanlab.init(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
        operator.on_init(project, workspace, logdir=logdir),operator.on_init(project, workspace, logdir=logdir),

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
    return self.__run_all(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
    return self.__run_all(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
    http = create_http(self.create_login_info())
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info
    http = create_http(self.create_login_info())
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info
    return terminal_login(key, save)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
    return terminal_login(key, save)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
    return code_login(api_key, save_key)    
return code_login(api_key, save_key)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
        login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading
    raise error
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
    raise error
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
    result = func(*args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
    result = func(*args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
    resp = login_request(api_key, api_host, timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
    resp = login_request(api_key, api_host, timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
    resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
    resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)    
return request("post", url, data=data, json=json, **kwargs)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)    
return session.request(method=method, url=url, **kwargs)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
resp = self.send(prep, **send_kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
r = adapter.send(request, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions    .raise ConnectionError(e, request=request)ConnectionError
: requests.exceptionsHTTPSConnectionPool(host='swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2b12daa6d820>: Failed to establish a new connection: [Errno -2] Name or service not known')).
ConnectionError: HTTPSConnectionPool(host='swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2adccf881820>: Failed to establish a new connection: [Errno -2] Name or service not known'))
Traceback (most recent call last):
Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
        http = get_http()http = get_http()

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
        raise ValueError("http object is not initialized")raise ValueError("http object is not initialized")

ValueErrorValueError: : http object is not initializedhttp object is not initialized


During handling of the above exception, another exception occurred:


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
Traceback (most recent call last):
  File "training_swanlab.py", line 168, in <module>
  File "training_swanlab.py", line 168, in <module>
        main()main()

  File "training_swanlab.py", line 27, in main
  File "training_swanlab.py", line 27, in main
        swanlab.init('deepseek_train')swanlab.init('deepseek_train')

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
        operator.on_init(project, workspace, logdir=logdir),operator.on_init(project, workspace, logdir=logdir),

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
        return self.__run_all(return self.__run_all(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}    
return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
    http = create_http(self.create_login_info())
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info
http = create_http(self.create_login_info())
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info
    return terminal_login(key, save)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
return terminal_login(key, save)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
    return code_login(api_key, save_key)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
    return code_login(api_key, save_key)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
    login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading
    login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading
    raise error
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
raise error
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
    result = func(*args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
    result = func(*args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
    resp = login_request(api_key, api_host, timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
    resp = login_request(api_key, api_host, timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
    resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
    resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
        return request("post", url, data=data, json=json, **kwargs)return request("post", url, data=data, json=json, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
        return session.request(method=method, url=url, **kwargs)return session.request(method=method, url=url, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
        resp = self.send(prep, **send_kwargs)resp = self.send(prep, **send_kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)    
r = adapter.send(request, **kwargs)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
        raise ConnectionError(e, request=request)raise ConnectionError(e, request=request)

requests.exceptionsrequests.exceptions..ConnectionErrorConnectionError: : HTTPSConnectionPool(host='swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2b7ec453d5e0>: Failed to establish a new connection: [Errno -2] Name or service not known'))HTTPSConnectionPool(host='swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2ac3fcd40520>: Failed to establish a new connection: [Errno -2] Name or service not known'))

Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
    http = get_http()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 105, in on_init
    http = get_http()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/http.py", line 340, in get_http
        raise ValueError("http object is not initialized")raise ValueError("http object is not initialized")

ValueErrorValueError: : http object is not initializedhttp object is not initialized


During handling of the above exception, another exception occurred:


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
Traceback (most recent call last):
  File "training_swanlab.py", line 168, in <module>
  File "training_swanlab.py", line 168, in <module>
        main()main()

  File "training_swanlab.py", line 28, in main
  File "training_swanlab.py", line 28, in main
        swanlab.init(swanlab.init(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
        operator.on_init(project, workspace, logdir=logdir),operator.on_init(project, workspace, logdir=logdir),

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
        return self.__run_all(return self.__run_all(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}    
return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 108, in on_init
    http = create_http(self.create_login_info())
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info
http = create_http(self.create_login_info())
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/cloud.py", line 59, in create_login_info
    return terminal_login(key, save)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
    return terminal_login(key, save)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 122, in terminal_login
        return code_login(api_key, save_key)return code_login(api_key, save_key)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
    login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)    
login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading
        raise errorraise error

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
        result = func(*args)result = func(*args)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
        resp = login_request(api_key, api_host, timeout)resp = login_request(api_key, api_host, timeout)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
        resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)    
return request("post", url, data=data, json=json, **kwargs)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
return session.request(method=method, url=url, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
        resp = self.send(prep, **send_kwargs)resp = self.send(prep, **send_kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
        r = adapter.send(request, **kwargs)r = adapter.send(request, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
        raise ConnectionError(e, request=request)raise ConnectionError(e, request=request)

requests.exceptionsrequests.exceptions..ConnectionErrorConnectionError: : HTTPSConnectionPool(host='swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2ac5ef2756d0>: Failed to establish a new connection: [Errno -2] Name or service not known'))
HTTPSConnectionPool(host='swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2b7ede2db700>: Failed to establish a new connection: [Errno -2] Name or service not known'))
Traceback (most recent call last):
Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
        conn = connection.create_connection(conn = connection.create_connection(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/urllib3/util/connection.py", line 72, in create_connection
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/urllib3/util/connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):    
for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):  File "/share/home/zhangshanqi/pytorch/lib/python3.8/socket.py", line 918, in getaddrinfo

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
    socketfor res in _socket.getaddrinfo(host, port, family, type, proto, flags):.
gaierror: [Errno -2] Name or service not knownsocket
.
During handling of the above exception, another exception occurred:

gaierrorTraceback (most recent call last):
:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/urllib3/connectionpool.py", line 716, in urlopen
[Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/urllib3/connectionpool.py", line 716, in urlopen
        httplib_response = self._make_request(httplib_response = self._make_request(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/urllib3/connectionpool.py", line 404, in _make_request
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/urllib3/connectionpool.py", line 404, in _make_request
        self._validate_conn(conn)self._validate_conn(conn)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/urllib3/connectionpool.py", line 1061, in _validate_conn
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/urllib3/connectionpool.py", line 1061, in _validate_conn
        conn.connect()conn.connect()

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/urllib3/connection.py", line 363, in connect
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/urllib3/connection.py", line 363, in connect
        self.sock = conn = self._new_conn()self.sock = conn = self._new_conn()

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
        raise NewConnectionError(raise NewConnectionError(

urllib3.exceptionsurllib3.exceptions..NewConnectionErrorNewConnectionError: : <urllib3.connection.HTTPSConnection object at 0x2b1fccb31cd0>: Failed to establish a new connection: [Errno -2] Name or service not known<urllib3.connection.HTTPSConnection object at 0x2b5561aecd00>: Failed to establish a new connection: [Errno -2] Name or service not known


During handling of the above exception, another exception occurred:


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 486, in send
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    resp = conn.urlopen(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/urllib3/util/retry.py", line 594, in increment
    retries = retries.increment(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/urllib3/util/retry.py", line 594, in increment
        raise MaxRetryError(_pool, url, error or ResponseError(cause))raise MaxRetryError(_pool, url, error or ResponseError(cause))

urllib3.exceptionsurllib3.exceptions..MaxRetryErrorMaxRetryError: : HTTPSConnectionPool(host='swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2b5561aecd00>: Failed to establish a new connection: [Errno -2] Name or service not known'))HTTPSConnectionPool(host='swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2b1fccb31cd0>: Failed to establish a new connection: [Errno -2] Name or service not known'))


During handling of the above exception, another exception occurred:


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
Traceback (most recent call last):
  File "training_swanlab.py", line 173, in <module>
  File "training_swanlab.py", line 173, in <module>
        main()main()

  File "training_swanlab.py", line 26, in main
  File "training_swanlab.py", line 26, in main
        swanlab.login(swanlab.login(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/utils.py", line 60, in wrapper
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/utils.py", line 60, in wrapper
        return func(*args, **kwargs)return func(*args, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 64, in login
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 64, in login
    login_info = code_login(api_key, save) if api_key else CloudRunCallback.create_login_info(save)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
    login_info = code_login(api_key, save) if api_key else CloudRunCallback.create_login_info(save)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
    login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)    
login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading
        raise errorraise error

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
        result = func(*args)result = func(*args)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
        resp = login_request(api_key, api_host, timeout)resp = login_request(api_key, api_host, timeout)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
    resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
    resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
    return request("post", url, data=data, json=json, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
    return session.request(method=method, url=url, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
        resp = self.send(prep, **send_kwargs)resp = self.send(prep, **send_kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
        r = adapter.send(request, **kwargs)r = adapter.send(request, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
        raise ConnectionError(e, request=request)raise ConnectionError(e, request=request)

requests.exceptionsrequests.exceptions..ConnectionErrorConnectionError: : HTTPSConnectionPool(host='swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2b1fccb31cd0>: Failed to establish a new connection: [Errno -2] Name or service not known'))HTTPSConnectionPool(host='swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2b5561aecd00>: Failed to establish a new connection: [Errno -2] Name or service not known'))

Traceback (most recent call last):
Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/urllib3/util/connection.py", line 72, in create_connection
    conn = connection.create_connection(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/urllib3/util/connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/socket.py", line 918, in getaddrinfo
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):    
for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.socketgaierror.: gaierror[Errno -2] Name or service not known: 
[Errno -2] Name or service not known
During handling of the above exception, another exception occurred:


Traceback (most recent call last):

During handling of the above exception, another exception occurred:

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/urllib3/connectionpool.py", line 716, in urlopen
Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/urllib3/connectionpool.py", line 404, in _make_request
    self._validate_conn(conn)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/urllib3/connectionpool.py", line 1061, in _validate_conn
    httplib_response = self._make_request(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/urllib3/connectionpool.py", line 404, in _make_request
    self._validate_conn(conn)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/urllib3/connectionpool.py", line 1061, in _validate_conn
    conn.connect()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/urllib3/connection.py", line 363, in connect
    self.sock = conn = self._new_conn()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    conn.connect()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/urllib3/connection.py", line 363, in connect
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x2b049916fd30>: Failed to establish a new connection: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 486, in send
    self.sock = conn = self._new_conn()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x2b9d69ce8ca0>: Failed to establish a new connection: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 486, in send
        resp = conn.urlopen(resp = conn.urlopen(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/urllib3/connectionpool.py", line 802, in urlopen
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/urllib3/connectionpool.py", line 802, in urlopen
        retries = retries.increment(retries = retries.increment(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/urllib3/util/retry.py", line 594, in increment
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))    
raise MaxRetryError(_pool, url, error or ResponseError(cause))urllib3.exceptions
.urllib3.exceptionsMaxRetryError.: MaxRetryErrorHTTPSConnectionPool(host='swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2b049916fd30>: Failed to establish a new connection: [Errno -2] Name or service not known')): 
HTTPSConnectionPool(host='swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2b9d69ce8ca0>: Failed to establish a new connection: [Errno -2] Name or service not known'))
During handling of the above exception, another exception occurred:


Traceback (most recent call last):

During handling of the above exception, another exception occurred:

  File "training_swanlab.py", line 173, in <module>
Traceback (most recent call last):
  File "training_swanlab.py", line 173, in <module>
        main()main()

  File "training_swanlab.py", line 26, in main
  File "training_swanlab.py", line 26, in main
        swanlab.login(swanlab.login(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/utils.py", line 60, in wrapper
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/utils.py", line 60, in wrapper
        return func(*args, **kwargs)return func(*args, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 64, in login
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 64, in login
        login_info = code_login(api_key, save) if api_key else CloudRunCallback.create_login_info(save)login_info = code_login(api_key, save) if api_key else CloudRunCallback.create_login_info(save)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 97, in code_login
        login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)login_info: LoginInfo = FONT.loading(tip, login_by_key, args=(api_key, 20, save_key), interval=0.5)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 84, in loading
    raise error
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
    raise error
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swankit/log/utils.py", line 66, in task
    result = func(*args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
    result = func(*args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 45, in login_by_key
    resp = login_request(api_key, api_host, timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
    resp = login_request(api_key, api_host, timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/api/auth/login.py", line 27, in login_request
    resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
    resp = requests.post(url=f"{api_host}/login/api_key", headers={"authorization": api_key}, timeout=timeout)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 115, in post
        return request("post", url, data=data, json=json, **kwargs)return request("post", url, data=data, json=json, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/api.py", line 59, in request
        return session.request(method=method, url=url, **kwargs)return session.request(method=method, url=url, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
        resp = self.send(prep, **send_kwargs)resp = self.send(prep, **send_kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)    
r = adapter.send(request, **kwargs)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions    .raise ConnectionError(e, request=request)ConnectionError
: requests.exceptionsHTTPSConnectionPool(host='swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2b9d69ce8ca0>: Failed to establish a new connection: [Errno -2] Name or service not known'))
.ConnectionError: HTTPSConnectionPool(host='swanlab.cn', port=443): Max retries exceeded with url: /api/login/api_key (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x2b049916fd30>: Failed to establish a new connection: [Errno -2] Name or service not known'))
Traceback (most recent call last):
Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/local.py", line 13, in <module>
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/local.py", line 13, in <module>
        import swanboardimport swanboard

ModuleNotFoundErrorModuleNotFoundError: : No module named 'swanboard'No module named 'swanboard'


During handling of the above exception, another exception occurred:


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
Traceback (most recent call last):
  File "training_swanlab.py", line 170, in <module>
  File "training_swanlab.py", line 170, in <module>
        main()main()

  File "training_swanlab.py", line 28, in main
  File "training_swanlab.py", line 28, in main
        swanlab.init(swanlab.init(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 192, in init
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 192, in init
    operator, c = _create_operator(mode, public, callbacks)    
operator, c = _create_operator(mode, public, callbacks)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/utils.py", line 202, in _create_operator

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/utils.py", line 202, in _create_operator
        from .callbacker.local import LocalRunCallbackfrom .callbacker.local import LocalRunCallback

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/local.py", line 15, in <module>
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/local.py", line 15, in <module>
        raise ImportError("Please install swanboard to use 'local' mode: pip install 'swanlab[dashboard]'")raise ImportError("Please install swanboard to use 'local' mode: pip install 'swanlab[dashboard]'")

ImportErrorImportError: : Please install swanboard to use 'local' mode: pip install 'swanlab[dashboard]'Please install swanboard to use 'local' mode: pip install 'swanlab[dashboard]'

Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peewee.py", line 3263, in connect
    self._state.set_connection(self._connect())
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peewee.py", line 3607, in _connect
    self._add_conn_hooks(conn)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peewee.py", line 3617, in _add_conn_hooks
    self._set_pragmas(conn)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peewee.py", line 3632, in _set_pragmas
    cursor.execute('PRAGMA %s = %s;' % (pragma, value))
sqlite3.OperationalError: database is locked

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "training_swanlab.py", line 170, in <module>
    main()
  File "training_swanlab.py", line 28, in main
    swanlab.init(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/sdk.py", line 194, in init
    operator.on_init(project, workspace, logdir=logdir),
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 75, in on_init
    return self.__run_all(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in __run_all
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/run/helper.py", line 59, in <dictcomp>
    return {name: getattr(callback, method)(*args, **kwargs) for name, callback in self.callbacks.items()}
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanlab/data/callbacker/local.py", line 130, in on_init
    self.board.on_init(proj_name)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanboard/callback.py", line 25, in on_init
    connect(autocreate=True, path=get_swanlog_dir())
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/swanboard/db/db_connect.py", line 69, in connect
    swandb.connect()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peewee.py", line 3266, in connect
    self._initialize_connection(self._state.conn)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peewee.py", line 3088, in __exit__
    reraise(new_type, new_type(exc_value, *exc_args), traceback)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peewee.py", line 196, in reraise
    raise value.with_traceback(tb)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peewee.py", line 3263, in connect
    self._state.set_connection(self._connect())
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peewee.py", line 3607, in _connect
    self._add_conn_hooks(conn)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peewee.py", line 3617, in _add_conn_hooks
    self._set_pragmas(conn)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peewee.py", line 3632, in _set_pragmas
    cursor.execute('PRAGMA %s = %s;' % (pragma, value))
peewee.OperationalError: database is locked
Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 6864.65it/s]
Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 6413.31it/s]
Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 12.10it/s]
Generating train split: 0 examples [00:00, ? examples/s]Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 11.77it/s]
Generating train split: 0 examples [00:00, ? examples/s]Failed to read file '/share/home/zhangshanqi/pyn/shopping_behavior2/models/traning_data/dataset.jsonl' with error <class 'pyarrow.lib.ArrowInvalid'>: JSON parse error: Column() changed from object to string in row 0
                                                        Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/packaged_modules/json/json.py", line 134, in _generate_tables
    dataset = json.load(f)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/__init__.py", line 293, in load
Failed to read file '/share/home/zhangshanqi/pyn/shopping_behavior2/models/traning_data/dataset.jsonl' with error <class 'pyarrow.lib.ArrowInvalid'>: JSON parse error: Column() changed from object to string in row 0
                                                        Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/packaged_modules/json/json.py", line 134, in _generate_tables
    dataset = json.load(f)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/__init__.py", line 293, in load
    return loads(fp.read(),
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/__init__.py", line 357, in loads
    return loads(fp.read(),
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/__init__.py", line 357, in loads
    return _default_decoder.decode(s)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/decoder.py", line 340, in decode
    return _default_decoder.decode(s)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/decoder.py", line 340, in decode
    raise JSONDecodeError("Extra data", s, end)
json.decoder.JSONDecodeError: Extra data: line 64 column 2 (char 27826)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/builder.py", line 1858, in _prepare_split_single
    raise JSONDecodeError("Extra data", s, end)
json.decoder.JSONDecodeError: Extra data: line 64 column 2 (char 27826)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/builder.py", line 1858, in _prepare_split_single
    for _, table in generator:
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/packaged_modules/json/json.py", line 137, in _generate_tables
    for _, table in generator:
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/packaged_modules/json/json.py", line 137, in _generate_tables
    raise e
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/packaged_modules/json/json.py", line 113, in _generate_tables
raise e
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/packaged_modules/json/json.py", line 113, in _generate_tables
    pa_table = paj.read_json(    
pa_table = paj.read_json(  File "pyarrow/_json.pyx", line 308, in pyarrow._json.read_json

  File "pyarrow/_json.pyx", line 308, in pyarrow._json.read_json
  File "pyarrow/error.pxi", line 154, in pyarrow.lib.pyarrow_internal_check_status
  File "pyarrow/error.pxi", line 154, in pyarrow.lib.pyarrow_internal_check_status
  File "pyarrow/error.pxi", line 91, in pyarrow.lib.check_status
  File "pyarrow/error.pxi", line 91, in pyarrow.lib.check_status
pyarrow.lib.pyarrow.libArrowInvalid.: ArrowInvalidJSON parse error: Column() changed from object to string in row 0: 
JSON parse error: Column() changed from object to string in row 0
The above exception was the direct cause of the following exception:


Traceback (most recent call last):

The above exception was the direct cause of the following exception:

  File "training_swanlab.py", line 182, in <module>
Traceback (most recent call last):
  File "training_swanlab.py", line 182, in <module>
        main()main()

  File "training_swanlab.py", line 41, in main
  File "training_swanlab.py", line 41, in main
        raw = datasets.load_dataset(raw = datasets.load_dataset(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/load.py", line 1797, in load_dataset
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/load.py", line 1797, in load_dataset
        builder_instance.download_and_prepare(builder_instance.download_and_prepare(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/builder.py", line 890, in download_and_prepare
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/builder.py", line 890, in download_and_prepare
        self._download_and_prepare(self._download_and_prepare(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/builder.py", line 985, in _download_and_prepare
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/builder.py", line 985, in _download_and_prepare
    self._prepare_split(split_generator, **prepare_split_kwargs)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/builder.py", line 1746, in _prepare_split
self._prepare_split(split_generator, **prepare_split_kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/builder.py", line 1746, in _prepare_split
    for job_id, done, content in self._prepare_split_single(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/builder.py", line 1891, in _prepare_split_single
    for job_id, done, content in self._prepare_split_single(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/builder.py", line 1891, in _prepare_split_single
    raise DatasetGenerationError("An error occurred while generating the dataset") from e
datasets.builder.DatasetGenerationError: An error occurred while generating the dataset
    raise DatasetGenerationError("An error occurred while generating the dataset") from e
datasets.builder.DatasetGenerationError: An error occurred while generating the dataset
Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 6636.56it/s]
Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 6472.69it/s]
Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 11.09it/s]
Generating train split: 0 examples [00:00, ? examples/s]Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 10.65it/s]
Generating train split: 0 examples [00:00, ? examples/s]                                                                                                                Traceback (most recent call last):
  File "training_swanlab.py", line 182, in <module>
Traceback (most recent call last):
  File "training_swanlab.py", line 182, in <module>
    main()
  File "training_swanlab.py", line 41, in main
    main()
  File "training_swanlab.py", line 41, in main
    raw = datasets.load_dataset(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/load.py", line 1810, in load_dataset
    raw = datasets.load_dataset(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/load.py", line 1797, in load_dataset
        ds = builder_instance.as_dataset(split=split, verification_mode=verification_mode, in_memory=keep_in_memory)builder_instance.download_and_prepare(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/builder.py", line 1107, in as_dataset
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/builder.py", line 890, in download_and_prepare
    self._download_and_prepare(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/builder.py", line 987, in _download_and_prepare
    raise NotImplementedError(f"Loading a dataset cached in a {type(self._fs).__name__} is not supported.")
NotImplementedError: Loading a dataset cached in a LocalFileSystem is not supported.
    raise OSError(
OSError: Cannot find data file. 
Original error:
[Errno 2] No such file or directory: '/share/home/zhangshanqi/.cache/huggingface/datasets/json/default-27199f17903bdabd/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/json-train-00000-00000-of-NNNNN.arrow'
Traceback (most recent call last):
Traceback (most recent call last):
  File "training_swanlab.py", line 184, in <module>
  File "training_swanlab.py", line 184, in <module>
    main()    
main()  File "training_swanlab.py", line 42, in main

  File "training_swanlab.py", line 42, in main
    raw = Dataset.from_json(data_path)
    NameErrorraw = Dataset.from_json(data_path): 
name 'Dataset' is not defined
NameError: name 'Dataset' is not defined
Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 7854.50it/s]Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 8256.50it/s]

Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s]Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s]

Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 0 examples [00:00, ? examples/s]                                                                                                                Traceback (most recent call last):
  File "training_swanlab.py", line 186, in <module>
Traceback (most recent call last):
  File "training_swanlab.py", line 186, in <module>
    main()    
main()  File "training_swanlab.py", line 44, in main

  File "training_swanlab.py", line 44, in main
    raw = Dataset.from_json(data_path)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 1106, in from_json
raw = Dataset.from_json(data_path)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 1106, in from_json
    return JsonDatasetReader(
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/io/json.py", line 67, in read
return JsonDatasetReader(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/io/json.py", line 59, in read
        dataset = self.builder.as_dataset(self.builder.download_and_prepare(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/builder.py", line 1107, in as_dataset
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/builder.py", line 890, in download_and_prepare
    self._download_and_prepare(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/builder.py", line 987, in _download_and_prepare
    raise NotImplementedError(f"Loading a dataset cached in a {type(self._fs).__name__} is not supported.")
NotImplementedError: Loading a dataset cached in a LocalFileSystem is not supported.
    raise OSError(
OSError: Cannot find data file. 
Original error:
[Errno 2] No such file or directory: '/share/home/zhangshanqi/.cache/huggingface/datasets/json/default-9ace079222601ae6/0.0.0/json-train-00000-00000-of-NNNNN.arrow'
Traceback (most recent call last):
Traceback (most recent call last):
  File "training_swanlab.py", line 196, in <module>
  File "training_swanlab.py", line 196, in <module>
        main()main()

  File "training_swanlab.py", line 50, in main
  File "training_swanlab.py", line 50, in main
        records.append(json.loads(line))records.append(json.loads(line))

NameErrorNameError: : name 'json' is not definedname 'json' is not defined

Traceback (most recent call last):
Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/utils/hub.py", line 403, in cached_file
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/utils/hub.py", line 403, in cached_file
        resolved_file = hf_hub_download(resolved_file = hf_hub_download(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 106, in _inner_fn
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 106, in _inner_fn
        validate_repo_id(arg_value)validate_repo_id(arg_value)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 154, in validate_repo_id
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 154, in validate_repo_id
        raise HFValidationError(raise HFValidationError(

huggingface_hub.errorshuggingface_hub.errors..HFValidationErrorHFValidationError: : Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'pyn/shopping_behavior2/llm/deepseek_R1'. Use `repo_type` argument if needed.Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'pyn/shopping_behavior2/llm/deepseek_R1'. Use `repo_type` argument if needed.


The above exception was the direct cause of the following exception:


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
Traceback (most recent call last):
  File "training_swanlab.py", line 196, in <module>
  File "training_swanlab.py", line 196, in <module>
        main()main()

  File "training_swanlab.py", line 67, in main
  File "training_swanlab.py", line 67, in main
    config    = AutoConfig.from_pretrained(model_path)    
config    = AutoConfig.from_pretrained(model_path)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py", line 1006, in from_pretrained

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py", line 1006, in from_pretrained
        config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/configuration_utils.py", line 570, in get_config_dict
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/configuration_utils.py", line 570, in get_config_dict
        config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/configuration_utils.py", line 629, in _get_config_dict
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/configuration_utils.py", line 629, in _get_config_dict
    resolved_config_file = cached_file(    
resolved_config_file = cached_file(  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/utils/hub.py", line 469, in cached_file

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/utils/hub.py", line 469, in cached_file
    raise EnvironmentError(
    OSErrorraise EnvironmentError(: 
Incorrect path_or_model_id: 'pyn/shopping_behavior2/llm/deepseek_R1'. Please provide either the path to a local folder or the repo_id of a model on the Hub.OSError
: Incorrect path_or_model_id: 'pyn/shopping_behavior2/llm/deepseek_R1'. Please provide either the path to a local folder or the repo_id of a model on the Hub.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [01:56<01:56, 116.53s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:56<01:56, 116.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [03:33<00:00, 104.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [03:33<00:00, 106.67s/it]
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 1/232 [00:00<00:44,  5.21 examples/s]Loading checkpoint shards: 100%|██████████| 2/2 [03:33<00:00, 105.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [03:33<00:00, 106.77s/it]
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 970.66 examples/s]                                                              Map:   0%|          | 0/26 [00:00<?, ? examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 2249.81 examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                                                                    Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.27 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.26 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 34.13 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 53.97 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:00, 58.91 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 76.97 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 90.43 examples/s]                                                                                                                                                    /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  5.07 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.92 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.54 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.61 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 15.19 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 15.18 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 19.06 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 18.95 examples/s]                                                                                                                                                /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
training_swanlab.py:187: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:187: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  File "training_swanlab.py", line 196, in <module>
    main()
  File "training_swanlab.py", line 189, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2052, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2204, in _inner_training_loop
    model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/accelerator.py", line 1350, in prepare
    result = tuple(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/accelerator.py", line 1351, in <genexpr>
    self._prepare_one(obj, first_pass=True, device_placement=d) for obj, d in zip(args, device_placement)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/accelerator.py", line 1226, in _prepare_one
    return self.prepare_model(obj, device_placement=device_placement)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/accelerator.py", line 1477, in prepare_model
    model = torch.nn.parallel.DistributedDataParallel(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 800, in __init__
    _sync_module_states(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/distributed/utils.py", line 298, in _sync_module_states
    _sync_params_and_buffers(process_group, module_states, broadcast_bucket_size, src)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/distributed/utils.py", line 309, in _sync_params_and_buffers
    dist._broadcast_coalesced(
CUDA out of memory. Tried to allocate 1.96 GiB. GPU  has a total capacity of 31.74 GiB of which 985.38 MiB is free. Including non-PyTorch memory, this process has 30.77 GiB memory in use. Of the allocated memory 30.35 GiB is allocated by PyTorch, and 991.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
  File "training_swanlab.py", line 196, in <module>
    main()
  File "training_swanlab.py", line 189, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2052, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2204, in _inner_training_loop
    model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/accelerator.py", line 1350, in prepare
    result = tuple(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/accelerator.py", line 1351, in <genexpr>
    self._prepare_one(obj, first_pass=True, device_placement=d) for obj, d in zip(args, device_placement)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/accelerator.py", line 1226, in _prepare_one
    return self.prepare_model(obj, device_placement=device_placement)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/accelerator.py", line 1477, in prepare_model
    model = torch.nn.parallel.DistributedDataParallel(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 800, in __init__
    _sync_module_states(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/distributed/utils.py", line 298, in _sync_module_states
    _sync_params_and_buffers(process_group, module_states, broadcast_bucket_size, src)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/distributed/utils.py", line 309, in _sync_params_and_buffers
    dist._broadcast_coalesced(
CUDA out of memory. Tried to allocate 1.96 GiB. GPU 
  File "training_swanlab.py", line 165
    deepspeed="/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/ds_config.json"
    ^
  File "training_swanlab.py", line 165
SyntaxError    : deepspeed="/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/ds_config.json"
invalid syntax    
^
SyntaxError: invalid syntax
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [02:23<02:23, 143.73s/it]Loading checkpoint shards:  50%|█████     | 1/2 [02:24<02:24, 144.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [04:37<00:00, 138.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [04:37<00:00, 138.92s/it]
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 1/232 [00:00<00:35,  6.55 examples/s]Loading checkpoint shards: 100%|██████████| 2/2 [04:38<00:00, 138.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [04:38<00:00, 139.03s/it]
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 1112.82 examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                  Map: 100%|██████████| 232/232 [00:00<00:00, 2159.46 examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                  Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 14.84 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 14.84 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 53.82 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 53.43 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 77.06 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 76.64 examples/s]                                                                                                                                                    /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  5.24 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  5.07 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.97 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.06 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 15.77 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.98 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 19.89 examples/s]                                                                        Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 18.62 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
                                                                        /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[rank0]: Traceback (most recent call last):
[rank0]:   File "training_swanlab.py", line 197, in <module>
[rank0]:     main()
[rank0]:   File "training_swanlab.py", line 152, in main
[rank0]:     training_args = TrainingArguments(
[rank0]:   File "<string>", line 132, in __init__
[rank0]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py", line 1996, in __post_init__
[rank0]:     self.hf_deepspeed_config = HfTrainerDeepSpeedConfig(self.deepspeed)
[rank0]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/integrations/deepspeed.py", line 91, in __init__
[rank0]:     super().__init__(config_file_or_dict)
[rank0]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/integrations/deepspeed.py", line 81, in __init__
[rank0]:     super().__init__(config_file_or_dict)
[rank0]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/utils/deepspeed.py", line 68, in __init__
[rank0]:     config = json.load(f)
[rank0]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/__init__.py", line 293, in load
[rank0]:     return loads(fp.read(),
[rank0]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/__init__.py", line 357, in loads
[rank0]:     return _default_decoder.decode(s)
[rank0]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/decoder.py", line 337, in decode
[rank0]:     obj, end = self.raw_decode(s, idx=_w(s, 0).end())
[rank0]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/decoder.py", line 355, in raw_decode
[rank0]:     raise JSONDecodeError("Expecting value", s, err.value) from None
[rank0]: json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
[rank1]: Traceback (most recent call last):
[rank1]:   File "training_swanlab.py", line 197, in <module>
[rank1]:     main()
[rank1]:   File "training_swanlab.py", line 152, in main
[rank1]:     training_args = TrainingArguments(
[rank1]:   File "<string>", line 132, in __init__
[rank1]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py", line 1996, in __post_init__
[rank1]:     self.hf_deepspeed_config = HfTrainerDeepSpeedConfig(self.deepspeed)
[rank1]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/integrations/deepspeed.py", line 91, in __init__
[rank1]:     super().__init__(config_file_or_dict)
[rank1]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/integrations/deepspeed.py", line 81, in __init__
[rank1]:     super().__init__(config_file_or_dict)
[rank1]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/utils/deepspeed.py", line 68, in __init__
[rank1]:     config = json.load(f)
[rank1]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/__init__.py", line 293, in load
[rank1]:     return loads(fp.read(),
[rank1]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/__init__.py", line 357, in loads
[rank1]:     return _default_decoder.decode(s)
[rank1]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/decoder.py", line 337, in decode
[rank1]:     obj, end = self.raw_decode(s, idx=_w(s, 0).end())
[rank1]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/decoder.py", line 355, in raw_decode
[rank1]:     raise JSONDecodeError("Expecting value", s, err.value) from None
[rank1]: json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [02:05<02:05, 125.04s/it]Loading checkpoint shards:  50%|█████     | 1/2 [02:05<02:05, 125.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [03:56<00:00, 116.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [03:56<00:00, 118.07s/it]
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Loading checkpoint shards: 100%|██████████| 2/2 [03:56<00:00, 116.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [03:56<00:00, 118.19s/it]
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 1/232 [00:00<00:24,  9.43 examples/s]Map:   0%|          | 1/232 [00:00<01:20,  2.85 examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 659.45 examples/s]                                                              Map:   0%|          | 0/26 [00:00<?, ? examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 1233.38 examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                                                                    Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 14.88 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 14.88 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 34.60 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:00, 58.51 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 51.15 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 84.93 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 72.18 examples/s]                                                                                                                                                    /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  5.00 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.94 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.48 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.34 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 15.06 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.83 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 19.06 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 18.74 examples/s]                                                                                                                                                /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
training_swanlab.py:188: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:188: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  File "training_swanlab.py", line 197, in <module>
    main()
  File "training_swanlab.py", line 190, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2052, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2150, in _inner_training_loop
    self.optimizer, self.lr_scheduler = deepspeed_init(self, num_training_steps=max_steps)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/integrations/deepspeed.py", line 393, in deepspeed_init
    hf_deepspeed_config.trainer_config_finalize(args, model, num_training_steps)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/integrations/deepspeed.py", line 265, in trainer_config_finalize
    raise ValueError(
Please correct the following DeepSpeed config values that mismatch TrainingArguments values:
- ds train_micro_batch_size_per_gpu=1 vs hf per_device_train_batch_size=4
- ds train_batch_size=8 vs hf train_batch_size (calculated)=16
The easiest method is to set these DeepSpeed config values to 'auto'.
  File "training_swanlab.py", line 197, in <module>
    main()
  File "training_swanlab.py", line 190, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2052, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2150, in _inner_training_loop
    self.optimizer, self.lr_scheduler = deepspeed_init(self, num_training_steps=max_steps)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/integrations/deepspeed.py", line 393, in deepspeed_init
    hf_deepspeed_config.trainer_config_finalize(args, model, num_training_steps)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/integrations/deepspeed.py", line 265, in trainer_config_finalize
    raise ValueError(
Please correct the following DeepSpeed config values that mismatch TrainingArguments values:
- ds train_micro_batch_size_per_gpu=1 vs hf per_device_train_batch_size=4
- ds train_batch_size=8 vs hf train_batch_size (calculated)=16
The easiest method is to set these DeepSpeed config values to 'auto'.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [02:07<02:07, 127.47s/it]Loading checkpoint shards:  50%|█████     | 1/2 [02:07<02:07, 127.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [03:41<00:00, 107.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [03:41<00:00, 110.58s/it]
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 1/232 [00:00<00:29,  7.80 examples/s]Loading checkpoint shards: 100%|██████████| 2/2 [03:41<00:00, 107.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [03:41<00:00, 110.66s/it]
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 1012.63 examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                  Map: 100%|██████████| 232/232 [00:00<00:00, 2013.98 examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                  Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.39 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.12 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:03<00:03, 35.98 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:00, 60.13 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 90.60 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 50.84 examples/s]                                                                          Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 73.86 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
                                                                          /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.99 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.93 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.41 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.08 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.88 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.05 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 18.76 examples/s]                                                                        Map (num_proc=4): 100%|██████████| 26/26 [00:02<00:00, 17.33 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
                                                                        /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
training_swanlab.py:188: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:188: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  File "training_swanlab.py", line 197, in <module>
    main()
  File "training_swanlab.py", line 190, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2052, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2204, in _inner_training_loop
    model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/accelerator.py", line 1344, in prepare
    result = self._prepare_deepspeed(*args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/accelerator.py", line 1851, in _prepare_deepspeed
    engine, optimizer, _, lr_scheduler = ds_initialize(**kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/__init__.py", line 179, in initialize
    config_class = DeepSpeedConfig(config, mpu, mesh_device=mesh_device)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/config.py", line 800, in __init__
    self._configure_train_batch_size()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/config.py", line 985, in _configure_train_batch_size
    self._batch_assertion()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/config.py", line 933, in _batch_assertion
    assert train_batch == micro_batch * grad_acc * self.world_size, (
Check batch related parameters. train_batch_size is not equal to micro_batch_per_gpu * gradient_acc_step * world_size 16 != 4 * 1 * 2
  File "training_swanlab.py", line 197, in <module>
    main()
  File "training_swanlab.py", line 190, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2052, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2204, in _inner_training_loop
    model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/accelerator.py", line 1344, in prepare
    result = self._prepare_deepspeed(*args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/accelerator.py", line 1851, in _prepare_deepspeed
    engine, optimizer, _, lr_scheduler = ds_initialize(**kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/__init__.py", line 179, in initialize
    config_class = DeepSpeedConfig(config, mpu, mesh_device=mesh_device)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/config.py", line 800, in __init__
    self._configure_train_batch_size()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/config.py", line 985, in _configure_train_batch_size
    self._batch_assertion()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/config.py", line 933, in _batch_assertion
    assert train_batch == micro_batch * grad_acc * self.world_size, (
Check batch related parameters. train_batch_size is not equal to micro_batch_per_gpu * gradient_acc_step * world_size 16 != 4 * 1 * 2
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [02:37<02:37, 157.48s/it]Loading checkpoint shards:  50%|█████     | 1/2 [02:37<02:37, 157.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [04:20<00:00, 125.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [04:20<00:00, 130.04s/it]
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Loading checkpoint shards: 100%|██████████| 2/2 [04:20<00:00, 125.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [04:20<00:00, 130.11s/it]
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 1/232 [00:00<01:11,  3.22 examples/s]Map:   0%|          | 1/232 [00:00<00:40,  5.69 examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 709.65 examples/s]                                                              Map:   0%|          | 0/26 [00:00<?, ? examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 975.73 examples/s]                                                              Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                                                                    Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:04<00:13, 13.29 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:04<00:13, 13.28 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 30.29 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 47.45 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 68.81 examples/s]                                                                          Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 72.72 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
                                                                          /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  5.07 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  5.20 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.73 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 11.08 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 15.52 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.66 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 19.54 examples/s]                                                                        Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 18.68 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
                                                                        /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
training_swanlab.py:188: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:188: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  File "training_swanlab.py", line 197, in <module>
    main()
  File "training_swanlab.py", line 190, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2052, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2150, in _inner_training_loop
    self.optimizer, self.lr_scheduler = deepspeed_init(self, num_training_steps=max_steps)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/integrations/deepspeed.py", line 393, in deepspeed_init
    hf_deepspeed_config.trainer_config_finalize(args, model, num_training_steps)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/integrations/deepspeed.py", line 265, in trainer_config_finalize
    raise ValueError(
Please correct the following DeepSpeed config values that mismatch TrainingArguments values:
- ds train_micro_batch_size_per_gpu=32 vs hf per_device_train_batch_size=4
- ds train_batch_size=4 vs hf train_batch_size (calculated)=32
The easiest method is to set these DeepSpeed config values to 'auto'.
  File "training_swanlab.py", line 197, in <module>
    main()
  File "training_swanlab.py", line 190, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2052, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2150, in _inner_training_loop
    self.optimizer, self.lr_scheduler = deepspeed_init(self, num_training_steps=max_steps)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/integrations/deepspeed.py", line 393, in deepspeed_init
    hf_deepspeed_config.trainer_config_finalize(args, model, num_training_steps)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/integrations/deepspeed.py", line 265, in trainer_config_finalize
    raise ValueError(
Please correct the following DeepSpeed config values that mismatch TrainingArguments values:
- ds train_micro_batch_size_per_gpu=32 vs hf per_device_train_batch_size=4
- ds train_batch_size=4 vs hf train_batch_size (calculated)=32
The easiest method is to set these DeepSpeed config values to 'auto'.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [02:21<02:21, 141.14s/it]Loading checkpoint shards:  50%|█████     | 1/2 [02:21<02:21, 141.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [04:08<00:00, 120.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [04:08<00:00, 124.04s/it]
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Loading checkpoint shards: 100%|██████████| 2/2 [04:08<00:00, 121.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [04:08<00:00, 124.14s/it]
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 1/232 [00:00<00:56,  4.11 examples/s]Map:   0%|          | 1/232 [00:00<00:33,  7.00 examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 831.61 examples/s]                                                              Map: 100%|██████████| 232/232 [00:00<00:00, 1098.14 examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                                                                    Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:10, 16.06 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.46 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:03<00:03, 34.04 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 33.43 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 76.72 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 77.57 examples/s]                                                                                                                                                    /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  5.04 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:04,  4.52 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01,  9.46 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.18 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 12.54 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 18.44 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:02<00:00, 16.05 examples/s]                                                                                                                                                /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
training_swanlab.py:188: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:188: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  File "training_swanlab.py", line 197, in <module>
    main()
  File "training_swanlab.py", line 190, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2052, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2204, in _inner_training_loop
    model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/accelerator.py", line 1344, in prepare
    result = self._prepare_deepspeed(*args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/accelerator.py", line 1851, in _prepare_deepspeed
    engine, optimizer, _, lr_scheduler = ds_initialize(**kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/__init__.py", line 179, in initialize
    config_class = DeepSpeedConfig(config, mpu, mesh_device=mesh_device)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/config.py", line 800, in __init__
    self._configure_train_batch_size()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/config.py", line 985, in _configure_train_batch_size
    self._batch_assertion()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/config.py", line 933, in _batch_assertion
    assert train_batch == micro_batch * grad_acc * self.world_size, (
Check batch related parameters. train_batch_size is not equal to micro_batch_per_gpu * gradient_acc_step * world_size 32 != 4 * 1 * 2
  File "training_swanlab.py", line 197, in <module>
    main()
  File "training_swanlab.py", line 190, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2052, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2204, in _inner_training_loop
    model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/accelerator.py", line 1344, in prepare
    result = self._prepare_deepspeed(*args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/accelerator.py", line 1851, in _prepare_deepspeed
    engine, optimizer, _, lr_scheduler = ds_initialize(**kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/__init__.py", line 179, in initialize
    config_class = DeepSpeedConfig(config, mpu, mesh_device=mesh_device)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/config.py", line 800, in __init__
    self._configure_train_batch_size()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/config.py", line 985, in _configure_train_batch_size
    self._batch_assertion()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/config.py", line 933, in _batch_assertion
    assert train_batch == micro_batch * grad_acc * self.world_size, (
Check batch related parameters. train_batch_size is not equal to micro_batch_per_gpu * gradient_acc_step * world_size 32 != 4 * 1 * 2
  File "training_swanlab.py", line 158
    evaluation_strategy='steps',
    ^
  File "training_swanlab.py", line 158
SyntaxError    : evaluation_strategy='steps',
invalid syntax    
^
SyntaxError: invalid syntax
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [02:11<02:11, 131.05s/it]Loading checkpoint shards:  50%|█████     | 1/2 [02:11<02:11, 131.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [04:07<00:00, 122.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [04:07<00:00, 123.94s/it]
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Loading checkpoint shards: 100%|██████████| 2/2 [04:08<00:00, 122.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [04:08<00:00, 124.04s/it]
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 1/232 [00:00<00:59,  3.91 examples/s]Map:  78%|███████▊  | 180/232 [00:00<00:00, 1306.83 examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 820.78 examples/s]                                                                                                                             Map:   0%|          | 0/26 [00:00<?, ? examples/s]Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                                                                    Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.49 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.49 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:03<00:03, 35.83 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:03<00:03, 34.58 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 56.56 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 55.27 examples/s]                                                                          Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 82.49 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
                                                                          /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.95 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.88 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.26 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.06 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.31 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 13.90 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 18.15 examples/s]                                                                        Traceback (most recent call last):
  File "training_swanlab.py", line 198, in <module>
    main()
  File "training_swanlab.py", line 152, in main
    training_args = TrainingArguments(
TypeError: __init__() got an unexpected keyword argument 'world_size'
Map (num_proc=4): 100%|██████████| 26/26 [00:02<00:00, 17.40 examples/s]                                                                        Traceback (most recent call last):
  File "training_swanlab.py", line 198, in <module>
    main()
  File "training_swanlab.py", line 152, in main
    training_args = TrainingArguments(
TypeError: __init__() got an unexpected keyword argument 'world_size'
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [02:07<02:07, 127.93s/it]Loading checkpoint shards:  50%|█████     | 1/2 [02:08<02:08, 128.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [03:44<00:00, 109.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [03:44<00:00, 112.20s/it]
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 1/232 [00:00<00:34,  6.77 examples/s]Loading checkpoint shards: 100%|██████████| 2/2 [03:44<00:00, 109.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [03:44<00:00, 112.33s/it]
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 1028.90 examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                  Map: 100%|██████████| 232/232 [00:00<00:00, 1741.75 examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                  Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.33 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.23 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 34.28 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 34.01 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 57.53 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 55.93 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 85.54 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 83.11 examples/s]                                                                          /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
                                                                          /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:04,  4.70 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.82 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 13.81 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.03 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 17.14 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 13.97 examples/s]                                                                        /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
Map (num_proc=4): 100%|██████████| 26/26 [00:02<00:00, 17.31 examples/s]                                                                        /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
training_swanlab.py:188: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:188: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  File "training_swanlab.py", line 197, in <module>
    main()
  File "training_swanlab.py", line 190, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2052, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2204, in _inner_training_loop
    model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/accelerator.py", line 1344, in prepare
    result = self._prepare_deepspeed(*args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/accelerator.py", line 1851, in _prepare_deepspeed
    engine, optimizer, _, lr_scheduler = ds_initialize(**kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/__init__.py", line 193, in initialize
    engine = DeepSpeedEngine(args=args,
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 326, in __init__
    self._configure_optimizer(optimizer, model_parameters)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 1408, in _configure_optimizer
    self.optimizer = self._configure_zero_optimizer(basic_optimizer)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 1666, in _configure_zero_optimizer
    optimizer = DeepSpeedZeroOptimizer(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 401, in __init__
    weights_partition = self.parallel_partitioned_bit16_groups[i][partition_id].to(
CUDA out of memory. Tried to allocate 14.96 GiB. GPU 
  File "training_swanlab.py", line 197, in <module>
    main()
  File "training_swanlab.py", line 190, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2052, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2204, in _inner_training_loop
    model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/accelerator.py", line 1344, in prepare
    result = self._prepare_deepspeed(*args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/accelerator.py", line 1851, in _prepare_deepspeed
    engine, optimizer, _, lr_scheduler = ds_initialize(**kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/__init__.py", line 193, in initialize
    engine = DeepSpeedEngine(args=args,
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 326, in __init__
    self._configure_optimizer(optimizer, model_parameters)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 1408, in _configure_optimizer
    self.optimizer = self._configure_zero_optimizer(basic_optimizer)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 1666, in _configure_zero_optimizer
    optimizer = DeepSpeedZeroOptimizer(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 401, in __init__
    weights_partition = self.parallel_partitioned_bit16_groups[i][partition_id].to(
CUDA out of memory. Tried to allocate 14.96 GiB. GPU  has a total capacity of 31.74 GiB of which 8.87 GiB is free. Including non-PyTorch memory, this process has 22.86 GiB memory in use. Of the allocated memory 22.44 GiB is allocated by PyTorch, and 7.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [01:53<01:53, 113.23s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:53<01:53, 113.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [03:35<00:00, 106.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [03:35<00:00, 107.55s/it]
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Loading checkpoint shards: 100%|██████████| 2/2 [03:35<00:00, 106.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [03:35<00:00, 107.68s/it]
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 1/232 [00:00<01:01,  3.75 examples/s]Map:  37%|███▋      | 85/232 [00:00<00:00, 637.81 examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 792.39 examples/s]                                                              Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                  Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.77 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.70 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:03<00:03, 35.99 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:03<00:03, 35.65 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:00, 58.85 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:00, 58.66 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 89.51 examples/s]                                                                          Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 84.55 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
                                                                          /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.88 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.84 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.28 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.71 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01,  9.90 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 18.97 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 13.94 examples/s]                                                                        /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
Map (num_proc=4): 100%|██████████| 26/26 [00:02<00:00, 17.33 examples/s]                                                                        /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[rank0]: Traceback (most recent call last):
[rank0]:   File "training_swanlab.py", line 197, in <module>
[rank0]:     main()
[rank0]:   File "training_swanlab.py", line 152, in main
[rank0]:     training_args = TrainingArguments(
[rank0]:   File "<string>", line 132, in __init__
[rank0]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py", line 1996, in __post_init__
[rank0]:     self.hf_deepspeed_config = HfTrainerDeepSpeedConfig(self.deepspeed)
[rank0]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/integrations/deepspeed.py", line 91, in __init__
[rank0]:     super().__init__(config_file_or_dict)
[rank0]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/integrations/deepspeed.py", line 81, in __init__
[rank0]:     super().__init__(config_file_or_dict)
[rank0]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/utils/deepspeed.py", line 68, in __init__
[rank0]:     config = json.load(f)
[rank0]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/__init__.py", line 293, in load
[rank0]:     return loads(fp.read(),
[rank0]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/__init__.py", line 357, in loads
[rank0]:     return _default_decoder.decode(s)
[rank0]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/decoder.py", line 337, in decode
[rank0]:     obj, end = self.raw_decode(s, idx=_w(s, 0).end())
[rank0]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/decoder.py", line 353, in raw_decode
[rank0]:     obj, end = self.scan_once(s, idx)
[rank0]: json.decoder.JSONDecodeError: Expecting ',' delimiter: line 11 column 5 (char 201)
[rank1]: Traceback (most recent call last):
[rank1]:   File "training_swanlab.py", line 197, in <module>
[rank1]:     main()
[rank1]:   File "training_swanlab.py", line 152, in main
[rank1]:     training_args = TrainingArguments(
[rank1]:   File "<string>", line 132, in __init__
[rank1]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py", line 1996, in __post_init__
[rank1]:     self.hf_deepspeed_config = HfTrainerDeepSpeedConfig(self.deepspeed)
[rank1]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/integrations/deepspeed.py", line 91, in __init__
[rank1]:     super().__init__(config_file_or_dict)
[rank1]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/integrations/deepspeed.py", line 81, in __init__
[rank1]:     super().__init__(config_file_or_dict)
[rank1]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/utils/deepspeed.py", line 68, in __init__
[rank1]:     config = json.load(f)
[rank1]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/__init__.py", line 293, in load
[rank1]:     return loads(fp.read(),
[rank1]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/__init__.py", line 357, in loads
[rank1]:     return _default_decoder.decode(s)
[rank1]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/decoder.py", line 337, in decode
[rank1]:     obj, end = self.raw_decode(s, idx=_w(s, 0).end())
[rank1]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/decoder.py", line 353, in raw_decode
[rank1]:     obj, end = self.scan_once(s, idx)
[rank1]: json.decoder.JSONDecodeError: Expecting ',' delimiter: line 11 column 5 (char 201)
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [01:51<01:51, 111.36s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:51<01:51, 111.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [03:44<00:00, 112.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [03:44<00:00, 112.32s/it]
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Loading checkpoint shards: 100%|██████████| 2/2 [03:44<00:00, 112.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [03:44<00:00, 112.43s/it]
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 1/232 [00:00<00:34,  6.73 examples/s]Map:   0%|          | 1/232 [00:00<01:06,  3.49 examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 1097.36 examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 716.05 examples/s]                                                                                                                Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                  Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:04<00:12, 14.19 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:04<00:12, 14.07 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 49.58 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 49.08 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 69.77 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 69.81 examples/s]                                                                                                                                                    /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.92 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.87 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.02 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.08 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.12 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.28 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 17.78 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:02<00:00, 16.81 examples/s]                                                                                                                                                /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
training_swanlab.py:188: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:188: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Creating extension directory /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121/cpu_adam...
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Creating extension directory /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121/cpu_adam...
Detected CUDA files, patching ldflags
Emitting ninja build file /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121/cpu_adam/build.ninja...
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module cpu_adam...
Loading extension module cpu_adam...
  0%|          | 0/145 [00:00<?, ?it/s]  File "training_swanlab.py", line 197, in <module>
    main()
  File "training_swanlab.py", line 190, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2052, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2388, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3485, in training_step
    loss = self.compute_loss(model, inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3532, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1189, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1000, in forward
    layer_outputs = decoder_layer(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 745, in forward
    hidden_states = self.mlp(hidden_states)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 311, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 116, in forward
    return F.linear(input, self.weight, self.bias)
CUDA out of memory. Tried to allocate 112.00 MiB. GPU 
  File "training_swanlab.py", line 197, in <module>
    main()
  File "training_swanlab.py", line 190, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2052, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2388, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3485, in training_step
    loss = self.compute_loss(model, inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3532, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1189, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1000, in forward
    layer_outputs = decoder_layer(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 745, in forward
    hidden_states = self.mlp(hidden_states)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 311, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 116, in forward
    return F.linear(input, self.weight, self.bias)
CUDA out of memory. Tried to allocate 112.00 MiB. GPU  has a total capacity of 31.74 GiB of which 109.38 MiB is free. Including non-PyTorch memory, this process has 31.55 GiB memory in use. Of the allocated memory 30.69 GiB is allocated by PyTorch, and 326.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
  0%|          | 0/145 [00:06<?, ?it/s]
Traceback (most recent call last):
  File "training_swanlab.py", line 200, in <module>
Traceback (most recent call last):
  File "training_swanlab.py", line 200, in <module>
        main()main()

  File "training_swanlab.py", line 66, in main
  File "training_swanlab.py", line 66, in main
    bnb_config = BitsAndBytesConfig(load_in_8bit=True)    
bnb_config = BitsAndBytesConfig(load_in_8bit=True)
NameErrorNameError: : name 'BitsAndBytesConfig' is not definedname 'BitsAndBytesConfig' is not defined

`low_cpu_mem_usage` was None, now set to True since model is quantized.
`low_cpu_mem_usage` was None, now set to True since model is quantized.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [02:12<02:12, 132.55s/it]Loading checkpoint shards:  50%|█████     | 1/2 [02:12<02:12, 132.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [03:49<00:00, 111.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [03:49<00:00, 114.52s/it]
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Loading checkpoint shards: 100%|██████████| 2/2 [03:49<00:00, 111.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [03:49<00:00, 114.62s/it]
Map:   0%|          | 1/232 [00:00<00:35,  6.57 examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 1105.70 examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 2297.38 examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                                                                    Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.56 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.53 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:03<00:03, 35.91 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 52.09 examples/s]                                                                          Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 54.57 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
                                                                          /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:04,  4.71 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  5.18 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.18 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 15.42 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.08 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 19.74 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.58 examples/s]                                                                        /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 20.28 examples/s]                                                                        /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
training_swanlab.py:192: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:192: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  File "training_swanlab.py", line 202, in <module>
    main()
  File "training_swanlab.py", line 185, in main
    trainer = Trainer(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 501, in __init__
    raise ValueError(
You cannot perform fine-tuning on purely quantized models. Please attach trainable adapters on top of the quantized model to correctly perform fine-tuning. Please see: https://huggingface.co/docs/transformers/peft for more details
  File "training_swanlab.py", line 202, in <module>
    main()
  File "training_swanlab.py", line 185, in main
    trainer = Trainer(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 501, in __init__
    raise ValueError(
You cannot perform fine-tuning on purely quantized models. Please attach trainable adapters on top of the quantized model to correctly perform fine-tuning. Please see: https://huggingface.co/docs/transformers/peft for more details
Traceback (most recent call last):
Traceback (most recent call last):
  File "training_swanlab.py", line 20, in <module>
  File "training_swanlab.py", line 20, in <module>
    from peft import (    
from peft import (
ImportError: cannot import name 'prepare_model_for_int8_training' from 'peft' (/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/__init__.py)
ImportError: cannot import name 'prepare_model_for_int8_training' from 'peft' (/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/__init__.py)
Traceback (most recent call last):
Traceback (most recent call last):
  File "training_swanlab.py", line 11, in <module>
  File "training_swanlab.py", line 11, in <module>
        from transformers import (from transformers import (

ImportErrorImportError: : cannot import name 'prepare_model_for_int8_training' from 'transformers' (/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/__init__.py)cannot import name 'prepare_model_for_int8_training' from 'transformers' (/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/__init__.py)

Traceback (most recent call last):
Traceback (most recent call last):
  File "training_swanlab.py", line 20, in <module>
  File "training_swanlab.py", line 20, in <module>
    from peft import (    
from peft import (
ImportErrorImportError: : cannot import name 'prepare_model_for_int8_training' from 'peft' (/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/__init__.py)cannot import name 'prepare_model_for_int8_training' from 'peft' (/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/__init__.py)

Traceback (most recent call last):
Traceback (most recent call last):
  File "training_swanlab.py", line 2, in <module>
  File "training_swanlab.py", line 2, in <module>
        from peft import (from peft import (

ImportErrorImportError: : cannot import name 'prepare_model_for_int8_training' from 'peft' (/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/__init__.py)cannot import name 'prepare_model_for_int8_training' from 'peft' (/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/__init__.py)

Traceback (most recent call last):
Traceback (most recent call last):
  File "training_swanlab.py", line 2, in <module>
  File "training_swanlab.py", line 2, in <module>
        from peft import (from peft import (

ImportErrorImportError: : cannot import name 'prepare_model_for_int8_training' from 'peft' (/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/__init__.py)cannot import name 'prepare_model_for_int8_training' from 'peft' (/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/__init__.py)

Traceback (most recent call last):
  File "training_swanlab.py", line 2, in <module>
Traceback (most recent call last):
  File "training_swanlab.py", line 2, in <module>
        from peft import (from peft import (

ImportErrorImportError: : cannot import name 'prepare_model_for_int8_training' from 'peft' (/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/__init__.py)cannot import name 'prepare_model_for_int8_training' from 'peft' (/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/__init__.py)

Traceback (most recent call last):
  File "training_swanlab.py", line 12, in <module>
Traceback (most recent call last):
  File "training_swanlab.py", line 12, in <module>
        from peft import prepare_model_for_int8_training, LoraConfig, get_peft_modelfrom peft import prepare_model_for_int8_training, LoraConfig, get_peft_model

ImportErrorImportError: : cannot import name 'prepare_model_for_int8_training' from 'peft' (/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/__init__.py)cannot import name 'prepare_model_for_int8_training' from 'peft' (/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/__init__.py)


During handling of the above exception, another exception occurred:


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
Traceback (most recent call last):
  File "training_swanlab.py", line 14, in <module>
  File "training_swanlab.py", line 14, in <module>
    from peft.utils import prepare_model_for_int8_training    
from peft.utils import prepare_model_for_int8_trainingImportError
: ImportError: cannot import name 'prepare_model_for_int8_training' from 'peft.utils' (/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/utils/__init__.py)
cannot import name 'prepare_model_for_int8_training' from 'peft.utils' (/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/utils/__init__.py)
Traceback (most recent call last):
Traceback (most recent call last):
  File "training_swanlab.py", line 2, in <module>
  File "training_swanlab.py", line 2, in <module>
        from transformers import (from transformers import (

ImportErrorImportError: : cannot import name 'prepare_model_for_int8_training' from 'transformers' (/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/__init__.py)cannot import name 'prepare_model_for_int8_training' from 'transformers' (/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/__init__.py)

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [02:24<02:24, 144.20s/it]Loading checkpoint shards:  50%|█████     | 1/2 [02:24<02:24, 144.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [04:22<00:00, 128.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [04:22<00:00, 131.18s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [04:22<00:00, 129.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [04:22<00:00, 131.28s/it]
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 1/232 [00:00<00:34,  6.74 examples/s]Map:   0%|          | 1/232 [00:00<00:34,  6.72 examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 1122.57 examples/s]                                                               Map: 100%|██████████| 232/232 [00:00<00:00, 1110.27 examples/s]Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                                                                    Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:10, 16.91 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:10, 16.62 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:03<00:03, 37.37 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:03<00:03, 36.97 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:03<00:00, 60.77 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:03<00:00, 61.05 examples/s]                                                                          /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 78.97 examples/s]                                                                          Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.79 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.40 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  5.05 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.11 examples/s]                                                                        Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01,  9.99 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 13.94 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 17.97 examples/s]                                                                        /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
training_swanlab.py:211: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:204: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:211: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:204: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  File "training_swanlab.py", line 221, in <module>
    main()
  File "training_swanlab.py", line 214, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2275, in _inner_training_loop
    model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/accelerator.py", line 1300, in prepare
    raise ValueError(
You can't train a model that has been loaded with `device_map='auto'` in any distributed mode. Please rerun your script specifying `--num_processes=1` or by launching with `python {{myscript.py}}`.
  File "training_swanlab.py", line 221, in <module>
    main()
  File "training_swanlab.py", line 214, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2275, in _inner_training_loop
    model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/accelerator.py", line 1300, in prepare
    raise ValueError(
You can't train a model that has been loaded with `device_map='auto'` in any distributed mode. Please rerun your script specifying `--num_processes=1` or by launching with `python {{myscript.py}}`.
`low_cpu_mem_usage` was None, now default to True since model is quantized.
`low_cpu_mem_usage` was None, now default to True since model is quantized.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [02:04<02:04, 124.48s/it]Loading checkpoint shards:  50%|█████     | 1/2 [02:04<02:04, 124.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [03:59<00:00, 119.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [03:59<00:00, 119.94s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [04:00<00:00, 119.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [04:00<00:00, 120.08s/it]
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 1/232 [00:00<00:34,  6.60 examples/s]Map:   0%|          | 1/232 [00:00<00:34,  6.61 examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 1108.17 examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 1086.46 examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                                                                    Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.74 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.64 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 52.77 examples/s]                                                                          Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 50.99 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
                                                                          /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  5.21 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.99 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 11.03 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.99 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.55 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 18.86 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 18.86 examples/s]                                                                                                                                                /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
training_swanlab.py:211: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:204: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:211: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:204: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121/cpu_adam/build.ninja...
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module cpu_adam...
Loading extension module cpu_adam...
  0%|          | 0/145 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  File "training_swanlab.py", line 221, in <module>
    main()
  File "training_swanlab.py", line 214, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/functional.py", line 2264, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)
`low_cpu_mem_usage` was None, now default to True since model is quantized.
`low_cpu_mem_usage` was None, now default to True since model is quantized.
`low_cpu_mem_usage` was None, now default to True since model is quantized.
`low_cpu_mem_usage` was None, now default to True since model is quantized.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [04:24<04:24, 264.79s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:25<04:25, 265.29s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:25<04:25, 265.32s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:25<04:25, 265.41s/it]Loading checkpoint shards:  50%|█████     | 1/2 [06:40<06:40, 400.69s/it]Loading checkpoint shards:  50%|█████     | 1/2 [06:40<06:40, 400.65s/it]
Loading checkpoint shards:  50%|█████     | 1/2 [06:40<06:40, 400.69s/it]

Traceback (most recent call last):
  File "training_swanlab.py", line 221, in <module>
Traceback (most recent call last):
Traceback (most recent call last):
  File "training_swanlab.py", line 221, in <module>
  File "training_swanlab.py", line 221, in <module>
        main()main()

  File "training_swanlab.py", line 79, in main
  File "training_swanlab.py", line 79, in main
    main()
  File "training_swanlab.py", line 79, in main
    model     = AutoModelForCausalLM.from_pretrained(model_path, config=config, quantization_config=bnb_config, device_map=None)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
model     = AutoModelForCausalLM.from_pretrained(model_path, config=config, quantization_config=bnb_config, device_map=None)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
    model     = AutoModelForCausalLM.from_pretrained(model_path, config=config, quantization_config=bnb_config, device_map=None)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
Loading checkpoint shards:  50%|█████     | 1/2 [06:40<06:40, 400.81s/it]
Traceback (most recent call last):
  File "training_swanlab.py", line 221, in <module>
    main()
  File "training_swanlab.py", line 79, in main
    model     = AutoModelForCausalLM.from_pretrained(model_path, config=config, quantization_config=bnb_config, device_map=None)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4225, in from_pretrained
        return model_class.from_pretrained(return model_class.from_pretrained(

      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4225, in from_pretrained
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4225, in from_pretrained
return model_class.from_pretrained(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4225, in from_pretrained
    ) = cls._load_pretrained_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4728, in _load_pretrained_model
    ) = cls._load_pretrained_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4728, in _load_pretrained_model
        ) = cls._load_pretrained_model() = cls._load_pretrained_model(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4728, in _load_pretrained_model
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4728, in _load_pretrained_model
    new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 995, in _load_state_dict_into_meta_model
    new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 995, in _load_state_dict_into_meta_model
        new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 995, in _load_state_dict_into_meta_model
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 995, in _load_state_dict_into_meta_model
    hf_quantizer.create_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/quantizers/quantizer_bnb_8bit.py", line 226, in create_quantized_param
hf_quantizer.create_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/quantizers/quantizer_bnb_8bit.py", line 226, in create_quantized_param
hf_quantizer.create_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/quantizers/quantizer_bnb_8bit.py", line 226, in create_quantized_param
    hf_quantizer.create_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/quantizers/quantizer_bnb_8bit.py", line 226, in create_quantized_param
        new_value = bnb.nn.Int8Params(new_value, requires_grad=False, **kwargs).to(target_device)    new_value = bnb.nn.Int8Params(new_value, requires_grad=False, **kwargs).to(target_device)
new_value = bnb.nn.Int8Params(new_value, requires_grad=False, **kwargs).to(target_device)
    
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 342, in to
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 342, in to
new_value = bnb.nn.Int8Params(new_value, requires_grad=False, **kwargs).to(target_device)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 342, in to

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 342, in to
        return self.cuda(device)return self.cuda(device)    

    return self.cuda(device)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 306, in cuda
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 306, in cuda
return self.cuda(device)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 306, in cuda
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 306, in cuda
    CB, CBt, SCB, SCBt, coo_tensorB = bnb.functional.double_quant(B)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/functional.py", line 2121, in double_quant
CB, CBt, SCB, SCBt, coo_tensorB = bnb.functional.double_quant(B)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/functional.py", line 2121, in double_quant
        CB, CBt, SCB, SCBt, coo_tensorB = bnb.functional.double_quant(B)CB, CBt, SCB, SCBt, coo_tensorB = bnb.functional.double_quant(B)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/functional.py", line 2121, in double_quant
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/functional.py", line 2121, in double_quant
        out_row = torch.zeros(A.shape, device=device, dtype=torch.int8)    out_row = torch.zeros(A.shape, device=device, dtype=torch.int8)
    out_row = torch.zeros(A.shape, device=device, dtype=torch.int8)
out_row = torch.zeros(A.shape, device=device, dtype=torch.int8)

torch.cudatorch.cuda.torch.cuda.OutOfMemoryErrortorch.cudaOutOfMemoryError.: .: OutOfMemoryErrorCUDA out of memory. Tried to allocate 56.00 MiB. GPU OutOfMemoryErrorCUDA out of memory. Tried to allocate 56.00 MiB. GPU : 
: 
CUDA out of memory. Tried to allocate 56.00 MiB. GPU CUDA out of memory. Tried to allocate 56.00 MiB. GPU 

Unused kwargs: ['load_in_8bit_cpu']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.
Unused kwargs: ['load_in_8bit_cpu']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.
Unused kwargs: ['load_in_8bit_cpu']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.
Unused kwargs: ['load_in_8bit_cpu']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.
`low_cpu_mem_usage` was None, now default to True since model is quantized.
`low_cpu_mem_usage` was None, now default to True since model is quantized.
`low_cpu_mem_usage` was None, now default to True since model is quantized.
`low_cpu_mem_usage` was None, now default to True since model is quantized.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [04:02<04:02, 242.03s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:02<04:02, 242.46s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:02<04:02, 242.47s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:02<04:02, 242.53s/it]Loading checkpoint shards:  50%|█████     | 1/2 [06:29<06:29, 389.57s/it]Loading checkpoint shards:  50%|█████     | 1/2 [06:29<06:29, 389.57s/it]
Loading checkpoint shards:  50%|█████     | 1/2 [06:29<06:29, 389.56s/it]
Loading checkpoint shards:  50%|█████     | 1/2 [06:29<06:29, 389.57s/it]

Traceback (most recent call last):
  File "training_swanlab.py", line 221, in <module>
Traceback (most recent call last):
  File "training_swanlab.py", line 221, in <module>
Traceback (most recent call last):
  File "training_swanlab.py", line 221, in <module>
Traceback (most recent call last):
  File "training_swanlab.py", line 221, in <module>
    main()
      File "training_swanlab.py", line 79, in main
main()
  File "training_swanlab.py", line 79, in main
    main()
      File "training_swanlab.py", line 79, in main
main()
  File "training_swanlab.py", line 79, in main
        model     = AutoModelForCausalLM.from_pretrained(model_path, config=config, quantization_config=bnb_config, device_map=None)model     = AutoModelForCausalLM.from_pretrained(model_path, config=config, quantization_config=bnb_config, device_map=None)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
    model     = AutoModelForCausalLM.from_pretrained(model_path, config=config, quantization_config=bnb_config, device_map=None)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
model     = AutoModelForCausalLM.from_pretrained(model_path, config=config, quantization_config=bnb_config, device_map=None)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4225, in from_pretrained
    return model_class.from_pretrained(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4225, in from_pretrained
    return model_class.from_pretrained(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4225, in from_pretrained
    return model_class.from_pretrained(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4225, in from_pretrained
    ) = cls._load_pretrained_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4728, in _load_pretrained_model
    ) = cls._load_pretrained_model(
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4728, in _load_pretrained_model
) = cls._load_pretrained_model(
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4728, in _load_pretrained_model
) = cls._load_pretrained_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4728, in _load_pretrained_model
        new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 995, in _load_state_dict_into_meta_model
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 995, in _load_state_dict_into_meta_model
    new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 995, in _load_state_dict_into_meta_model
    new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 995, in _load_state_dict_into_meta_model
        hf_quantizer.create_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)hf_quantizer.create_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/quantizers/quantizer_bnb_8bit.py", line 226, in create_quantized_param
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/quantizers/quantizer_bnb_8bit.py", line 226, in create_quantized_param
    hf_quantizer.create_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/quantizers/quantizer_bnb_8bit.py", line 226, in create_quantized_param
    hf_quantizer.create_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/quantizers/quantizer_bnb_8bit.py", line 226, in create_quantized_param
        new_value = bnb.nn.Int8Params(new_value, requires_grad=False, **kwargs).to(target_device)new_value = bnb.nn.Int8Params(new_value, requires_grad=False, **kwargs).to(target_device)        new_value = bnb.nn.Int8Params(new_value, requires_grad=False, **kwargs).to(target_device)new_value = bnb.nn.Int8Params(new_value, requires_grad=False, **kwargs).to(target_device)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 342, in to
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 342, in to


  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 342, in to
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 342, in to
    return self.cuda(device)    
return self.cuda(device)          File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 306, in cuda

return self.cuda(device)return self.cuda(device)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 306, in cuda


  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 306, in cuda
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 306, in cuda
    CB, CBt, SCB, SCBt, coo_tensorB = bnb.functional.double_quant(B)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/functional.py", line 2121, in double_quant
    CB, CBt, SCB, SCBt, coo_tensorB = bnb.functional.double_quant(B)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/functional.py", line 2121, in double_quant
CB, CBt, SCB, SCBt, coo_tensorB = bnb.functional.double_quant(B)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/functional.py", line 2121, in double_quant
CB, CBt, SCB, SCBt, coo_tensorB = bnb.functional.double_quant(B)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/functional.py", line 2121, in double_quant
    out_row = torch.zeros(A.shape, device=device, dtype=torch.int8)
        out_row = torch.zeros(A.shape, device=device, dtype=torch.int8)    torch.cudaout_row = torch.zeros(A.shape, device=device, dtype=torch.int8)
out_row = torch.zeros(A.shape, device=device, dtype=torch.int8).

OutOfMemoryErrortorch.cuda: .CUDA out of memory. Tried to allocate 56.00 MiB. GPU torch.cudaOutOfMemoryError
torch.cuda.: .OutOfMemoryErrorCUDA out of memory. Tried to allocate 56.00 MiB. GPU OutOfMemoryError: 
: CUDA out of memory. Tried to allocate 56.00 MiB. GPU CUDA out of memory. Tried to allocate 56.00 MiB. GPU 

Unused kwargs: ['load_in_8bit_cpu']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.
Unused kwargs: ['load_in_8bit_cpu']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.
Unused kwargs: ['load_in_8bit_cpu']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.
Unused kwargs: ['load_in_8bit_cpu']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.
Traceback (most recent call last):
  File "training_swanlab.py", line 221, in <module>
Traceback (most recent call last):
Traceback (most recent call last):
  File "training_swanlab.py", line 221, in <module>
  File "training_swanlab.py", line 221, in <module>
Traceback (most recent call last):
  File "training_swanlab.py", line 221, in <module>
        main()    main()    
main()
main()  File "training_swanlab.py", line 79, in main

  File "training_swanlab.py", line 79, in main

  File "training_swanlab.py", line 79, in main
  File "training_swanlab.py", line 79, in main
    model     = AutoModelForCausalLM.from_pretrained(model_path, config=config, quantization_config=bnb_config,  device_map={"": "cpu"})    
model     = AutoModelForCausalLM.from_pretrained(model_path, config=config, quantization_config=bnb_config,  device_map={"": "cpu"})          File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained

model     = AutoModelForCausalLM.from_pretrained(model_path, config=config, quantization_config=bnb_config,  device_map={"": "cpu"})model     = AutoModelForCausalLM.from_pretrained(model_path, config=config, quantization_config=bnb_config,  device_map={"": "cpu"})  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained


  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(    
return model_class.from_pretrained(      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 3657, in from_pretrained

return model_class.from_pretrained(  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 3657, in from_pretrained

      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 3657, in from_pretrained
return model_class.from_pretrained(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 3657, in from_pretrained
        hf_quantizer.validate_environment(hf_quantizer.validate_environment(
    
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/quantizers/quantizer_bnb_8bit.py", line 101, in validate_environment
hf_quantizer.validate_environment(  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/quantizers/quantizer_bnb_8bit.py", line 101, in validate_environment
hf_quantizer.validate_environment(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/quantizers/quantizer_bnb_8bit.py", line 101, in validate_environment
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/quantizers/quantizer_bnb_8bit.py", line 101, in validate_environment
    raise ValueError(    
    raise ValueError(    raise ValueError(
ValueErrorraise ValueError(
: ValueError
Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. ValueError: 
ValueError: Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. : Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. 
Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. 

Unused kwargs: ['load_in_8bit_cpu']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.
Unused kwargs: ['load_in_8bit_cpu']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.
Unused kwargs: ['load_in_8bit_cpu']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.
Unused kwargs: ['load_in_8bit_cpu']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [03:49<03:49, 229.87s/it]Loading checkpoint shards:  50%|█████     | 1/2 [03:50<03:50, 230.27s/it]Loading checkpoint shards:  50%|█████     | 1/2 [03:50<03:50, 230.27s/it]Loading checkpoint shards:  50%|█████     | 1/2 [03:50<03:50, 230.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:09<00:00, 212.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:09<00:00, 214.93s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Loading checkpoint shards: 100%|██████████| 2/2 [07:10<00:00, 212.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:10<00:00, 215.09s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [07:10<00:00, 212.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:10<00:00, 215.10s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [07:10<00:00, 212.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:10<00:00, 215.11s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Some parameters are on the meta device because they were offloaded to the cpu.
Some parameters are on the meta device because they were offloaded to the cpu.
Traceback (most recent call last):
  File "training_swanlab.py", line 223, in <module>
Traceback (most recent call last):
  File "training_swanlab.py", line 223, in <module>
    main()
  File "training_swanlab.py", line 82, in main
    model = get_peft_model(model, peft_config)
UnboundLocalError: local variable 'peft_config' referenced before assignment
    main()
  File "training_swanlab.py", line 82, in main
    model = get_peft_model(model, peft_config)
UnboundLocalError: local variable 'peft_config' referenced before assignment
Traceback (most recent call last):
  File "training_swanlab.py", line 223, in <module>
    main()
  File "training_swanlab.py", line 82, in main
    model = get_peft_model(model, peft_config)
UnboundLocalError: local variable 'peft_config' referenced before assignment
Traceback (most recent call last):
  File "training_swanlab.py", line 223, in <module>
    main()
  File "training_swanlab.py", line 82, in main
    model = get_peft_model(model, peft_config)
UnboundLocalError: local variable 'peft_config' referenced before assignment
Unused kwargs: ['load_in_8bit_cpu']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.
Unused kwargs: ['load_in_8bit_cpu']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.
Unused kwargs: ['load_in_8bit_cpu']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.
Unused kwargs: ['load_in_8bit_cpu']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [03:54<03:54, 234.12s/it]Loading checkpoint shards:  50%|█████     | 1/2 [03:54<03:54, 234.55s/it]Loading checkpoint shards:  50%|█████     | 1/2 [03:54<03:54, 234.62s/it]Loading checkpoint shards:  50%|█████     | 1/2 [03:54<03:54, 234.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:18<00:00, 216.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:18<00:00, 219.01s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Loading checkpoint shards: 100%|██████████| 2/2 [07:18<00:00, 216.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:18<00:00, 219.17s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [07:18<00:00, 216.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:18<00:00, 219.18s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [07:18<00:00, 216.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:18<00:00, 219.20s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Some parameters are on the meta device because they were offloaded to the cpu.
Some parameters are on the meta device because they were offloaded to the cpu.
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 1/232 [00:00<01:02,  3.72 examples/s]Map:   0%|          | 1/232 [00:00<01:02,  3.72 examples/s]Map:   0%|          | 1/232 [00:00<01:02,  3.72 examples/s]Map:   0%|          | 1/232 [00:00<01:02,  3.72 examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 802.91 examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 800.25 examples/s]                                                                                                                            Map:   0%|          | 0/26 [00:00<?, ? examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 793.72 examples/s]Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                              Map: 100%|██████████| 232/232 [00:00<00:00, 788.80 examples/s]Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                              Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                                                                                                                                                                        Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 14.81 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 34.42 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:04<00:12, 14.07 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:04<00:12, 13.84 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:00, 58.06 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:04<00:12, 13.69 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 31.71 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 86.44 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 67.24 examples/s]                                                                          Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 48.30 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
                                                                          Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 77.56 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
                                                                          /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 65.63 examples/s]                                                                          /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  5.07 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.55 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:04,  4.59 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.97 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:04,  4.69 examples/s]Map (num_proc=4):  50%|█████     | 13/26 [00:01<00:01,  8.50 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.92 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01,  9.98 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 18.54 examples/s]                                                                        Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01,  9.94 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 13.84 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:02<00:00, 16.41 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 13.90 examples/s]                                                                        Map (num_proc=4): 100%|██████████| 26/26 [00:02<00:00, 17.53 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
                                                                        /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
Map (num_proc=4): 100%|██████████| 26/26 [00:02<00:00, 16.12 examples/s]                                                                        /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
training_swanlab.py:213: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:213: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:213: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:213: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:206: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:206: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:206: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:206: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121/cpu_adam/build.ninja...
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Loading extension module cpu_adam...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  0%|          | 0/75 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  File "training_swanlab.py", line 223, in <module>
    main()
  File "training_swanlab.py", line 216, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/functional.py", line 2264, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)
  File "training_swanlab.py", line 223, in <module>
    main()
  File "training_swanlab.py", line 216, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/functional.py", line 2264, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)
  File "training_swanlab.py", line 223, in <module>
    main()
  File "training_swanlab.py", line 216, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/functional.py", line 2264, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
Expected all tensors to be on the same device, but found at least two devices, cuda:3 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)
  File "training_swanlab.py", line 223, in <module>
    main()
  File "training_swanlab.py", line 216, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/functional.py", line 2264, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
Expected all tensors to be on the same device, but found at least two devices, cuda:2 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)
  0%|          | 0/75 [00:01<?, ?it/s]
`low_cpu_mem_usage` was None, now default to True since model is quantized.
`low_cpu_mem_usage` was None, now default to True since model is quantized.
`low_cpu_mem_usage` was None, now default to True since model is quantized.
`low_cpu_mem_usage` was None, now default to True since model is quantized.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [04:04<04:04, 244.04s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:04<04:04, 244.54s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:04<04:04, 244.60s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:04<04:04, 244.59s/it]Loading checkpoint shards:  50%|█████     | 1/2 [06:22<06:22, 382.69s/it]
Loading checkpoint shards:  50%|█████     | 1/2 [06:22<06:22, 382.71s/it]
Traceback (most recent call last):
  File "training_swanlab.py", line 230, in <module>
Traceback (most recent call last):
  File "training_swanlab.py", line 230, in <module>
Loading checkpoint shards:  50%|█████     | 1/2 [06:22<06:22, 382.70s/it]
Traceback (most recent call last):
  File "training_swanlab.py", line 230, in <module>
        main()main()

  File "training_swanlab.py", line 80, in main
  File "training_swanlab.py", line 80, in main
    main()
  File "training_swanlab.py", line 80, in main
    model = AutoModelForCausalLM.from_pretrained(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
    model = AutoModelForCausalLM.from_pretrained(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
    model = AutoModelForCausalLM.from_pretrained(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
        return model_class.from_pretrained(return model_class.from_pretrained(

      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4225, in from_pretrained
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4225, in from_pretrained
return model_class.from_pretrained(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4225, in from_pretrained
    ) = cls._load_pretrained_model(
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4728, in _load_pretrained_model
) = cls._load_pretrained_model(    
) = cls._load_pretrained_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4728, in _load_pretrained_model
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4728, in _load_pretrained_model
    new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 995, in _load_state_dict_into_meta_model
new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 995, in _load_state_dict_into_meta_model
new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 995, in _load_state_dict_into_meta_model
    hf_quantizer.create_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/quantizers/quantizer_bnb_8bit.py", line 226, in create_quantized_param
    hf_quantizer.create_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/quantizers/quantizer_bnb_8bit.py", line 226, in create_quantized_param
    hf_quantizer.create_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/quantizers/quantizer_bnb_8bit.py", line 226, in create_quantized_param
    new_value = bnb.nn.Int8Params(new_value, requires_grad=False, **kwargs).to(target_device)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 342, in to
        new_value = bnb.nn.Int8Params(new_value, requires_grad=False, **kwargs).to(target_device)new_value = bnb.nn.Int8Params(new_value, requires_grad=False, **kwargs).to(target_device)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 342, in to
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 342, in to
    return self.cuda(device)    
return self.cuda(device)      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 306, in cuda

return self.cuda(device)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 306, in cuda

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 306, in cuda
    CB, CBt, SCB, SCBt, coo_tensorB = bnb.functional.double_quant(B)    
CB, CBt, SCB, SCBt, coo_tensorB = bnb.functional.double_quant(B)    
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/functional.py", line 2121, in double_quant
CB, CBt, SCB, SCBt, coo_tensorB = bnb.functional.double_quant(B)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/functional.py", line 2121, in double_quant
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/functional.py", line 2121, in double_quant
            out_row = torch.zeros(A.shape, device=device, dtype=torch.int8)out_row = torch.zeros(A.shape, device=device, dtype=torch.int8)out_row = torch.zeros(A.shape, device=device, dtype=torch.int8)


torch.cuda.OutOfMemoryError: torch.cudaCUDA out of memory. Tried to allocate 56.00 MiB. GPU torch.cuda.
OutOfMemoryError.: OutOfMemoryErrorCUDA out of memory. Tried to allocate 56.00 MiB. GPU : 
CUDA out of memory. Tried to allocate 56.00 MiB. GPU 
Loading checkpoint shards:  50%|█████     | 1/2 [06:22<06:22, 382.91s/it]
Traceback (most recent call last):
  File "training_swanlab.py", line 230, in <module>
    main()
  File "training_swanlab.py", line 80, in main
    model = AutoModelForCausalLM.from_pretrained(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4225, in from_pretrained
    ) = cls._load_pretrained_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4728, in _load_pretrained_model
    new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 995, in _load_state_dict_into_meta_model
    hf_quantizer.create_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/quantizers/quantizer_bnb_8bit.py", line 226, in create_quantized_param
    new_value = bnb.nn.Int8Params(new_value, requires_grad=False, **kwargs).to(target_device)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 342, in to
    return self.cuda(device)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 306, in cuda
    CB, CBt, SCB, SCBt, coo_tensorB = bnb.functional.double_quant(B)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/functional.py", line 2121, in double_quant
    out_row = torch.zeros(A.shape, device=device, dtype=torch.int8)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 56.00 MiB. GPU 
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [03:56<03:56, 236.69s/it]Loading checkpoint shards:  50%|█████     | 1/2 [03:57<03:57, 237.08s/it]Loading checkpoint shards:  50%|█████     | 1/2 [03:57<03:57, 237.14s/it]Loading checkpoint shards:  50%|█████     | 1/2 [03:57<03:57, 237.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:18<00:00, 216.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:18<00:00, 219.40s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [07:19<00:00, 216.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:19<00:00, 219.51s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [07:19<00:00, 216.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:19<00:00, 219.53s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [07:19<00:00, 216.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:19<00:00, 219.54s/it]
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 1/232 [00:00<00:35,  6.42 examples/s]Map:   0%|          | 1/232 [00:00<00:35,  6.44 examples/s]Map:   0%|          | 1/232 [00:00<00:35,  6.43 examples/s]Map:   0%|          | 1/232 [00:00<00:35,  6.49 examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 1089.20 examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 1082.35 examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 1083.14 examples/s]                                                                                                                                                                                             Map:   0%|          | 0/26 [00:00<?, ? examples/s]Map:   0%|          | 0/26 [00:00<?, ? examples/s]Map:   0%|          | 0/26 [00:00<?, ? examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 1051.25 examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                                                                                                                                                                        Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:10, 16.43 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:10, 16.34 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:10, 16.02 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:10, 16.01 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:03<00:03, 36.10 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:03<00:03, 36.19 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:03<00:03, 34.73 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:03<00:03, 34.47 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 56.49 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 80.28 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 54.22 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 54.34 examples/s]                                                                          /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
                                                                          /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
                                                                          Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 80.05 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
                                                                          /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  5.14 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  5.22 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.93 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  5.28 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:04,  4.72 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01,  9.94 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 15.26 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 11.10 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.33 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 15.61 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 19.20 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 18.40 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 18.01 examples/s]                                                                                                                                                                                                                        /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 19.28 examples/s]                                                                        /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
training_swanlab.py:222: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:215: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:222: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:222: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:215: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:215: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:222: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:215: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  File "training_swanlab.py", line 232, in <module>
    main()
  File "training_swanlab.py", line 225, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2275, in _inner_training_loop
    model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/accelerator.py", line 1300, in prepare
    raise ValueError(
You can't train a model that has been loaded with `device_map='auto'` in any distributed mode. Please rerun your script specifying `--num_processes=1` or by launching with `python {{myscript.py}}`.
  File "training_swanlab.py", line 232, in <module>
    main()
  File "training_swanlab.py", line 225, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2275, in _inner_training_loop
    model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/accelerator.py", line 1300, in prepare
    raise ValueError(
You can't train a model that has been loaded with `device_map='auto'` in any distributed mode. Please rerun your script specifying `--num_processes=1` or by launching with `python {{myscript.py}}`.
  File "training_swanlab.py", line 232, in <module>
    main()
  File "training_swanlab.py", line 225, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2275, in _inner_training_loop
    model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/accelerator.py", line 1300, in prepare
    raise ValueError(
You can't train a model that has been loaded with `device_map='auto'` in any distributed mode. Please rerun your script specifying `--num_processes=1` or by launching with `python {{myscript.py}}`.
  File "training_swanlab.py", line 232, in <module>
    main()
  File "training_swanlab.py", line 225, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2275, in _inner_training_loop
    model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/accelerator.py", line 1300, in prepare
    raise ValueError(
You can't train a model that has been loaded with `device_map='auto'` in any distributed mode. Please rerun your script specifying `--num_processes=1` or by launching with `python {{myscript.py}}`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [03:52<03:52, 232.67s/it]Loading checkpoint shards:  50%|█████     | 1/2 [03:53<03:53, 233.06s/it]Loading checkpoint shards:  50%|█████     | 1/2 [03:53<03:53, 233.06s/it]Loading checkpoint shards:  50%|█████     | 1/2 [03:53<03:53, 233.13s/it]Loading checkpoint shards:  50%|█████     | 1/2 [06:25<06:25, 385.45s/it]Loading checkpoint shards:  50%|█████     | 1/2 [06:25<06:25, 385.48s/it]
Loading checkpoint shards:  50%|█████     | 1/2 [06:25<06:25, 385.48s/it]

Loading checkpoint shards:  50%|█████     | 1/2 [06:25<06:25, 385.48s/it]
Traceback (most recent call last):
  File "training_swanlab.py", line 231, in <module>
Traceback (most recent call last):
  File "training_swanlab.py", line 231, in <module>
Traceback (most recent call last):
  File "training_swanlab.py", line 231, in <module>
Traceback (most recent call last):
  File "training_swanlab.py", line 231, in <module>
        main()    main()
main()
  File "training_swanlab.py", line 81, in main

  File "training_swanlab.py", line 81, in main
  File "training_swanlab.py", line 81, in main
    main()
  File "training_swanlab.py", line 81, in main
    model = AutoModelForCausalLM.from_pretrained(    
model = AutoModelForCausalLM.from_pretrained(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
model = AutoModelForCausalLM.from_pretrained(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
    model = AutoModelForCausalLM.from_pretrained(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
        return model_class.from_pretrained(return model_class.from_pretrained(

      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4225, in from_pretrained
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4225, in from_pretrained
return model_class.from_pretrained(    
return model_class.from_pretrained(  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4225, in from_pretrained

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4225, in from_pretrained
    ) = cls._load_pretrained_model(
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4728, in _load_pretrained_model
) = cls._load_pretrained_model(    
) = cls._load_pretrained_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4728, in _load_pretrained_model
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4728, in _load_pretrained_model
    new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 995, in _load_state_dict_into_meta_model
        new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 995, in _load_state_dict_into_meta_model
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 995, in _load_state_dict_into_meta_model
    ) = cls._load_pretrained_model(    
hf_quantizer.create_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/quantizers/quantizer_bnb_8bit.py", line 226, in create_quantized_param
        hf_quantizer.create_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)hf_quantizer.create_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/quantizers/quantizer_bnb_8bit.py", line 226, in create_quantized_param
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/quantizers/quantizer_bnb_8bit.py", line 226, in create_quantized_param
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4728, in _load_pretrained_model
    new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 995, in _load_state_dict_into_meta_model
    hf_quantizer.create_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/quantizers/quantizer_bnb_8bit.py", line 226, in create_quantized_param
    new_value = bnb.nn.Int8Params(new_value, requires_grad=False, **kwargs).to(target_device)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 342, in to
    new_value = bnb.nn.Int8Params(new_value, requires_grad=False, **kwargs).to(target_device)    
    new_value = bnb.nn.Int8Params(new_value, requires_grad=False, **kwargs).to(target_device)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 342, in to
new_value = bnb.nn.Int8Params(new_value, requires_grad=False, **kwargs).to(target_device)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 342, in to
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 342, in to
    return self.cuda(device)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 306, in cuda
    return self.cuda(device)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 306, in cuda
    return self.cuda(device)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 306, in cuda
return self.cuda(device)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 306, in cuda
    CB, CBt, SCB, SCBt, coo_tensorB = bnb.functional.double_quant(B)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/functional.py", line 2121, in double_quant
    CB, CBt, SCB, SCBt, coo_tensorB = bnb.functional.double_quant(B)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/functional.py", line 2121, in double_quant
    CB, CBt, SCB, SCBt, coo_tensorB = bnb.functional.double_quant(B)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/functional.py", line 2121, in double_quant
CB, CBt, SCB, SCBt, coo_tensorB = bnb.functional.double_quant(B)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/functional.py", line 2121, in double_quant
    out_row = torch.zeros(A.shape, device=device, dtype=torch.int8)
        out_row = torch.zeros(A.shape, device=device, dtype=torch.int8)out_row = torch.zeros(A.shape, device=device, dtype=torch.int8)
    
torch.cudaout_row = torch.zeros(A.shape, device=device, dtype=torch.int8)torch.cuda.
torch.cuda.OutOfMemoryError.OutOfMemoryError: OutOfMemoryError: torch.cudaCUDA out of memory. Tried to allocate 56.00 MiB. GPU : CUDA out of memory. Tried to allocate 56.00 MiB. GPU .
CUDA out of memory. Tried to allocate 56.00 MiB. GPU 
OutOfMemoryError
: CUDA out of memory. Tried to allocate 56.00 MiB. GPU 
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [03:42<03:42, 222.52s/it]Loading checkpoint shards:  50%|█████     | 1/2 [03:42<03:42, 222.98s/it]Loading checkpoint shards:  50%|█████     | 1/2 [03:43<03:43, 223.01s/it]Loading checkpoint shards:  50%|█████     | 1/2 [03:43<03:43, 223.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [06:57<00:00, 206.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [06:57<00:00, 208.62s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Loading checkpoint shards: 100%|██████████| 2/2 [06:57<00:00, 206.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [06:57<00:00, 208.88s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [06:57<00:00, 206.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [06:57<00:00, 208.89s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [06:57<00:00, 206.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [06:57<00:00, 208.89s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Some parameters are on the meta device because they were offloaded to the cpu.
Some parameters are on the meta device because they were offloaded to the cpu.
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 1/232 [00:00<00:31,  7.25 examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 1061.46 examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]                                                  Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 2202.32 examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 2262.82 examples/s]                                                                                                                 Map: 100%|██████████| 232/232 [00:00<00:00, 2267.28 examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                                                                    Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.25 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 14.66 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 14.65 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 14.54 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 33.19 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 52.71 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 51.68 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 51.95 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 57.84 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 76.11 examples/s]                                                                          Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 73.25 examples/s]                                                                          /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
                                                                          /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 68.40 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
                                                                          /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  5.01 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.93 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.77 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.07 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.17 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01,  9.68 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:04,  4.48 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.16 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 13.27 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 12.34 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 13.24 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 17.76 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:02<00:00, 17.02 examples/s]                                                                                                                                                                                                                        Map (num_proc=4): 100%|██████████| 26/26 [00:02<00:00, 16.32 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
                                                                        /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
training_swanlab.py:222: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:215: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:222: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:215: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:222: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:215: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:222: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:215: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121/cpu_adam/build.ninja...
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Loading extension module cpu_adam...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  0%|          | 0/75 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  File "training_swanlab.py", line 232, in <module>
    main()
  File "training_swanlab.py", line 225, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/functional.py", line 2264, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)
  File "training_swanlab.py", line 232, in <module>
    main()
  File "training_swanlab.py", line 225, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/functional.py", line 2264, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
Expected all tensors to be on the same device, but found at least two devices, cuda:2 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)
  File "training_swanlab.py", line 232, in <module>
    main()
  File "training_swanlab.py", line 225, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/functional.py", line 2264, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
Expected all tensors to be on the same device, but found at least two devices, cuda:3 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)  File "training_swanlab.py", line 232, in <module>
    main()
  File "training_swanlab.py", line 225, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/functional.py", line 2264, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)

  0%|          | 0/75 [00:01<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [04:30<04:30, 270.04s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:30<04:30, 270.44s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:30<04:30, 270.48s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:30<04:30, 270.46s/it]Loading checkpoint shards:  50%|█████     | 1/2 [06:40<06:40, 400.14s/it]Loading checkpoint shards:  50%|█████     | 1/2 [06:40<06:40, 400.14s/it]

Loading checkpoint shards:  50%|█████     | 1/2 [06:40<06:40, 400.10s/it]
Traceback (most recent call last):
Traceback (most recent call last):
  File "training_swanlab.py", line 232, in <module>
  File "training_swanlab.py", line 232, in <module>
Traceback (most recent call last):
  File "training_swanlab.py", line 232, in <module>
    main()
  File "training_swanlab.py", line 81, in main
        main()main()

  File "training_swanlab.py", line 81, in main
  File "training_swanlab.py", line 81, in main
    model = AutoModelForCausalLM.from_pretrained(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
        model = AutoModelForCausalLM.from_pretrained(model = AutoModelForCausalLM.from_pretrained(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4225, in from_pretrained
    return model_class.from_pretrained(
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4225, in from_pretrained
return model_class.from_pretrained(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4225, in from_pretrained
    ) = cls._load_pretrained_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4728, in _load_pretrained_model
    ) = cls._load_pretrained_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4728, in _load_pretrained_model
    ) = cls._load_pretrained_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4728, in _load_pretrained_model
    new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 995, in _load_state_dict_into_meta_model
    new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 995, in _load_state_dict_into_meta_model
    new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 995, in _load_state_dict_into_meta_model
    hf_quantizer.create_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/quantizers/quantizer_bnb_8bit.py", line 226, in create_quantized_param
    hf_quantizer.create_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/quantizers/quantizer_bnb_8bit.py", line 226, in create_quantized_param
    hf_quantizer.create_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/quantizers/quantizer_bnb_8bit.py", line 226, in create_quantized_param
        new_value = bnb.nn.Int8Params(new_value, requires_grad=False, **kwargs).to(target_device)new_value = bnb.nn.Int8Params(new_value, requires_grad=False, **kwargs).to(target_device)

      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 342, in to
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 342, in to
new_value = bnb.nn.Int8Params(new_value, requires_grad=False, **kwargs).to(target_device)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 342, in to
        return self.cuda(device)return self.cuda(device)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 306, in cuda
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 306, in cuda
    return self.cuda(device)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 306, in cuda
        CB, CBt, SCB, SCBt, coo_tensorB = bnb.functional.double_quant(B)CB, CBt, SCB, SCBt, coo_tensorB = bnb.functional.double_quant(B)

      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/functional.py", line 2121, in double_quant
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/functional.py", line 2121, in double_quant
CB, CBt, SCB, SCBt, coo_tensorB = bnb.functional.double_quant(B)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/functional.py", line 2121, in double_quant
    out_row = torch.zeros(A.shape, device=device, dtype=torch.int8)
    out_row = torch.zeros(A.shape, device=device, dtype=torch.int8)    
out_row = torch.zeros(A.shape, device=device, dtype=torch.int8)
torch.cuda.OutOfMemoryError: torch.cudaCUDA out of memory. Tried to allocate 56.00 MiB. GPU torch.cuda.
.OutOfMemoryError: CUDA out of memory. Tried to allocate 56.00 MiB. GPU 
OutOfMemoryError: CUDA out of memory. Tried to allocate 56.00 MiB. GPU 
Loading checkpoint shards:  50%|█████     | 1/2 [06:40<06:40, 400.40s/it]
Traceback (most recent call last):
  File "training_swanlab.py", line 232, in <module>
    main()
  File "training_swanlab.py", line 81, in main
    model = AutoModelForCausalLM.from_pretrained(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4225, in from_pretrained
    ) = cls._load_pretrained_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4728, in _load_pretrained_model
    new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 995, in _load_state_dict_into_meta_model
    hf_quantizer.create_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/quantizers/quantizer_bnb_8bit.py", line 226, in create_quantized_param
    new_value = bnb.nn.Int8Params(new_value, requires_grad=False, **kwargs).to(target_device)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 342, in to
    return self.cuda(device)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 306, in cuda
    CB, CBt, SCB, SCBt, coo_tensorB = bnb.functional.double_quant(B)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/functional.py", line 2121, in double_quant
    out_row = torch.zeros(A.shape, device=device, dtype=torch.int8)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 56.00 MiB. GPU 
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [04:05<04:05, 245.66s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:06<04:06, 246.15s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:06<04:06, 246.21s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:06<04:06, 246.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:33<00:00, 223.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:33<00:00, 226.75s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Loading checkpoint shards: 100%|██████████| 2/2 [07:33<00:00, 223.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:33<00:00, 226.96s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Loading checkpoint shards: 100%|██████████| 2/2 [07:34<00:00, 223.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:34<00:00, 227.03s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [07:34<00:00, 223.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:34<00:00, 227.03s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Some parameters are on the meta device because they were offloaded to the cpu.
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 1/232 [00:00<00:23,  9.63 examples/s]Map:  83%|████████▎ | 192/232 [00:00<00:00, 1053.48 examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                  Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 2106.43 examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 2099.35 examples/s]                                                                                                                              Map:   0%|          | 0/26 [00:00<?, ? examples/s]Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                                                                    Map: 100%|██████████| 232/232 [00:00<00:00, 2044.41 examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                  Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.77 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.76 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.64 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.62 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:03<00:03, 35.45 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:03<00:03, 35.33 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:03<00:03, 35.13 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 33.18 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:00, 59.26 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:00, 58.05 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 56.94 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 82.74 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 89.18 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 88.20 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 87.10 examples/s]                                                                                                                                                                                                                                                                                                        /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.91 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  5.00 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.75 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:04,  4.63 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.46 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.48 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01,  9.99 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.19 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01,  9.24 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 13.43 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 13.11 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.25 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 18.41 examples/s]                                                                        Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 17.69 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:02<00:00, 16.68 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
                                                                        Map (num_proc=4): 100%|██████████| 26/26 [00:02<00:00, 16.85 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
                                                                                                                                                /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
training_swanlab.py:223: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:216: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:223: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:216: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:223: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:216: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:223: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:216: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121/cpu_adam/build.ninja...
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Loading extension module cpu_adam...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  0%|          | 0/75 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  File "training_swanlab.py", line 233, in <module>
    main()
  File "training_swanlab.py", line 226, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/functional.py", line 2264, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)  File "training_swanlab.py", line 233, in <module>
    main()
  File "training_swanlab.py", line 226, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/functional.py", line 2264, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
Expected all tensors to be on the same device, but found at least two devices, cuda:3 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)
  File "training_swanlab.py", line 233, in <module>
    main()
  File "training_swanlab.py", line 226, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/functional.py", line 2264, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)

  File "training_swanlab.py", line 233, in <module>
    main()
  File "training_swanlab.py", line 226, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/functional.py", line 2264, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
Expected all tensors to be on the same device, but found at least two devices, cuda:2 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)
  0%|          | 0/75 [00:01<?, ?it/s]
  File "training_swanlab.py", line 203
    local_rank=local_rank,
    ^
  File "training_swanlab.py", line 203
SyntaxError    : local_rank=local_rank,
invalid syntax    
^
  File "training_swanlab.py", line 203
SyntaxError  File "training_swanlab.py", line 203
    :     local_rank=local_rank,
invalid syntaxlocal_rank=local_rank,
    
    ^
^
SyntaxErrorSyntaxError: : invalid syntaxinvalid syntax

Traceback (most recent call last):
  File "training_swanlab.py", line 3, in <module>
Traceback (most recent call last):
Traceback (most recent call last):
  File "training_swanlab.py", line 3, in <module>
Traceback (most recent call last):
  File "training_swanlab.py", line 3, in <module>
  File "training_swanlab.py", line 3, in <module>
        if 'LOCAL_RANK' in os.environ:if 'LOCAL_RANK' in os.environ:    
    
if 'LOCAL_RANK' in os.environ:if 'LOCAL_RANK' in os.environ:NameError
NameError
: : NameErrorNameErrorname 'os' is not definedname 'os' is not defined: : 

name 'os' is not definedname 'os' is not defined

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [04:16<04:16, 256.79s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:17<04:17, 257.14s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:17<04:17, 257.19s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:17<04:17, 257.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:43<00:00, 227.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:43<00:00, 231.60s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Loading checkpoint shards: 100%|██████████| 2/2 [07:43<00:00, 227.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:43<00:00, 231.78s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Loading checkpoint shards: 100%|██████████| 2/2 [07:43<00:00, 227.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:43<00:00, 231.82s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [07:43<00:00, 227.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:43<00:00, 231.83s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Some parameters are on the meta device because they were offloaded to the cpu.
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 1/232 [00:00<00:32,  7.15 examples/s]Map:   0%|          | 1/232 [00:00<00:32,  7.09 examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 1140.68 examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 1139.95 examples/s]                                                                                                                              Map:   0%|          | 0/26 [00:00<?, ? examples/s]Map:   0%|          | 0/26 [00:00<?, ? examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 2100.62 examples/s]                                                                                                    Map: 100%|██████████| 232/232 [00:00<00:00, 2177.71 examples/s]                                                                                                                              Map:   0%|          | 0/26 [00:00<?, ? examples/s]Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                                                                    Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.30 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.18 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.14 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 14.99 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 34.36 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 34.50 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 33.00 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 32.86 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 56.78 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 79.60 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 52.66 examples/s]                                                                          Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 76.16 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
                                                                                                                                                    /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 74.93 examples/s]                                                                          /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.84 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.78 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:04,  4.72 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01,  9.99 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01,  9.96 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 13.16 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:04,  4.67 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.30 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.10 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 16.19 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01,  9.39 examples/s]                                                                        Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 18.05 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:02<00:00, 17.65 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.25 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
                                                                                                                                                /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
Map (num_proc=4): 100%|██████████| 26/26 [00:02<00:00, 17.52 examples/s]                                                                        /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
training_swanlab.py:226: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:219: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:226: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:219: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:226: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:226: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:219: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:219: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121/cpu_adam/build.ninja...
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Loading extension module cpu_adam...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  0%|          | 0/75 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  File "training_swanlab.py", line 236, in <module>
    main()
  File "training_swanlab.py", line 229, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/functional.py", line 2264, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)
  File "training_swanlab.py", line 236, in <module>
    main()
  File "training_swanlab.py", line 229, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/functional.py", line 2264, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
Expected all tensors to be on the same device, but found at least two devices, cuda:2 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)  File "training_swanlab.py", line 236, in <module>
    main()
  File "training_swanlab.py", line 229, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/functional.py", line 2264, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)
  File "training_swanlab.py", line 236, in <module>
    main()
  File "training_swanlab.py", line 229, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/functional.py", line 2264, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
Expected all tensors to be on the same device, but found at least two devices, cuda:3 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)

  0%|          | 0/75 [00:01<?, ?it/s]
W0503 22:51:04.443386 47996621431744 torch/distributed/run.py:757] 
W0503 22:51:04.443386 47996621431744 torch/distributed/run.py:757] *****************************************
W0503 22:51:04.443386 47996621431744 torch/distributed/run.py:757] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0503 22:51:04.443386 47996621431744 torch/distributed/run.py:757] *****************************************
/share/home/zhangshanqi/pytorch/bin/python: can't open file ' ': [Errno 2] No such file or directory
/share/home/zhangshanqi/pytorch/bin/python: can't open file ' ': [Errno 2] No such file or directory
/share/home/zhangshanqi/pytorch/bin/python: can't open file ' ': [Errno 2] No such file or directory
/share/home/zhangshanqi/pytorch/bin/python: can't open file ' ': [Errno 2] No such file or directory
E0503 22:51:04.928360 47996621431744 torch/distributed/elastic/multiprocessing/api.py:826] failed (exitcode: 2) local_rank: 0 (pid: 89721) of binary: /share/home/zhangshanqi/pytorch/bin/python
Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/commands/accelerate_cli.py", line 48, in main
    args.func(args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/commands/launch.py", line 1153, in launch_command
    deepspeed_launcher(args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/commands/launch.py", line 846, in deepspeed_launcher
    distrib_run.run(args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/distributed/run.py", line 870, in run
    elastic_launch(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 263, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
  FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2025-05-03_22:51:04
  host      : gpu05
  rank      : 1 (local_rank: 1)
  exitcode  : 2 (pid: 89722)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2025-05-03_22:51:04
  host      : gpu05
  rank      : 2 (local_rank: 2)
  exitcode  : 2 (pid: 89723)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2025-05-03_22:51:04
  host      : gpu05
  rank      : 3 (local_rank: 3)
  exitcode  : 2 (pid: 89724)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-05-03_22:51:04
  host      : gpu05
  rank      : 0 (local_rank: 0)
  exitcode  : 2 (pid: 89721)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/share/home/zhangshanqi/.lsbatch/1746283812.14560949.shell: line 42: training_swanlab.py: command not found
W0503 23:03:31.804132 46942430962624 torch/distributed/run.py:757] 
W0503 23:03:31.804132 46942430962624 torch/distributed/run.py:757] *****************************************
W0503 23:03:31.804132 46942430962624 torch/distributed/run.py:757] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0503 23:03:31.804132 46942430962624 torch/distributed/run.py:757] *****************************************
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:51<00:51, 51.63s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:51<00:51, 51.93s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:52<00:52, 52.04s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:52<00:52, 52.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:33<00:00, 45.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:33<00:00, 46.78s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Loading checkpoint shards: 100%|██████████| 2/2 [01:33<00:00, 46.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:33<00:00, 46.96s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:33<00:00, 46.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:33<00:00, 46.94s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:33<00:00, 46.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:33<00:00, 46.97s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Some parameters are on the meta device because they were offloaded to the cpu.
Some parameters are on the meta device because they were offloaded to the cpu.
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 1/232 [00:00<00:25,  9.19 examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 1240.56 examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                  Map: 100%|██████████| 232/232 [00:00<00:00, 2056.20 examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                  Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 1944.55 examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                  Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 2148.69 examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                  Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.30 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.59 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 14.61 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:03<00:03, 36.36 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:03<00:03, 34.72 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:10, 16.36 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:00, 60.29 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 32.18 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 56.29 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 88.77 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 79.90 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:03<00:03, 35.28 examples/s]                                                                                                                                                    /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 78.80 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
                                                                          /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 54.64 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 83.44 examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]                                                                          /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  5.04 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.81 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:04,  4.75 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01,  9.43 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01,  9.67 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01,  9.49 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.32 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 12.56 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.85 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:02<00:00, 16.59 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:02<00:00, 17.43 examples/s]                                                                        Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.11 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:02<00:00, 17.91 examples/s]                                                                        /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
                                                                        /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.26 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 17.80 examples/s]                                                                        /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py:223: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py:216: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py:223: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py:216: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py:223: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py:216: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py:223: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py:216: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121/cpu_adam/build.ninja...
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Loading extension module cpu_adam...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  0%|          | 0/75 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  File "/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py", line 233, in <module>
    main()
  File "/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py", line 226, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/functional.py", line 2264, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)
  File "/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py", line 233, in <module>
    main()
  File "/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py", line 226, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/functional.py", line 2264, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
Expected all tensors to be on the same device, but found at least two devices, cuda:3 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)
  File "/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py", line 233, in <module>
    main()
  File "/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py", line 226, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/functional.py", line 2264, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
Expected all tensors to be on the same device, but found at least two devices, cuda:2 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)
  File "/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py", line 233, in <module>
    main()
  File "/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py", line 226, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/functional.py", line 2264, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)
  0%|          | 0/75 [00:01<?, ?it/s]
W0503 23:07:13.518968 46942430962624 torch/distributed/elastic/multiprocessing/api.py:851] Sending process 92642 closing signal SIGTERM
W0503 23:07:13.519343 46942430962624 torch/distributed/elastic/multiprocessing/api.py:851] Sending process 92644 closing signal SIGTERM
W0503 23:07:13.519432 46942430962624 torch/distributed/elastic/multiprocessing/api.py:851] Sending process 92645 closing signal SIGTERM
E0503 23:07:14.183942 46942430962624 torch/distributed/elastic/multiprocessing/api.py:826] failed (exitcode: 1) local_rank: 1 (pid: 92643) of binary: /share/home/zhangshanqi/pytorch/bin/python
Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/commands/accelerate_cli.py", line 48, in main
    args.func(args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/commands/launch.py", line 1153, in launch_command
    deepspeed_launcher(args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/commands/launch.py", line 846, in deepspeed_launcher
    distrib_run.run(args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/distributed/run.py", line 870, in run
    elastic_launch(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 263, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-05-03_23:07:13
  host      : gpu05
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 92643)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
W0503 23:17:25.004220 47193197646784 torch/distributed/run.py:757] 
W0503 23:17:25.004220 47193197646784 torch/distributed/run.py:757] *****************************************
W0503 23:17:25.004220 47193197646784 torch/distributed/run.py:757] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0503 23:17:25.004220 47193197646784 torch/distributed/run.py:757] *****************************************
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:50<00:50, 50.97s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:51<00:51, 51.37s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:51<00:51, 51.46s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:51<00:51, 51.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:33<00:00, 45.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:33<00:00, 46.69s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Loading checkpoint shards: 100%|██████████| 2/2 [01:33<00:00, 46.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:33<00:00, 46.88s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:33<00:00, 46.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:33<00:00, 46.88s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:33<00:00, 46.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:33<00:00, 46.88s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Some parameters are on the meta device because they were offloaded to the cpu.
Some parameters are on the meta device because they were offloaded to the cpu.
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 1/232 [00:00<00:27,  8.54 examples/s]Map:   0%|          | 1/232 [00:00<00:27,  8.54 examples/s]Map:   0%|          | 1/232 [00:00<00:27,  8.52 examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 1259.22 examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 1241.21 examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 1237.76 examples/s]                                                                                                                              Map:   0%|          | 0/26 [00:00<?, ? examples/s]Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                                                                                                                      Map: 100%|██████████| 232/232 [00:00<00:00, 2221.02 examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                  Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.66 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.58 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:03<00:03, 35.87 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 14.93 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.03 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:03<00:03, 35.38 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 34.55 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 57.27 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 32.74 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 54.40 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 81.80 examples/s]                                                                          Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 79.09 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 75.07 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 79.47 examples/s]                                                                                                                                                                                                                              /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.76 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  5.04 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:04,  4.53 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.57 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01,  9.26 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:04,  4.43 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01,  9.91 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 13.74 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.51 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 13.96 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 13.37 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:02<00:00, 17.39 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 18.33 examples/s]                                                                        Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 16.85 examples/s]                                                                                                                                                /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
                                                                        /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py:235: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py:228: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py:235: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py:228: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py:235: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py:228: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py:235: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py:228: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121/cpu_adam/build.ninja...
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Loading extension module cpu_adam...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  0%|          | 0/75 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  File "/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py", line 245, in <module>
    main()
  File "/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py", line 238, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/functional.py", line 2264, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)
  File "/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py", line 245, in <module>
    main()
  File "/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py", line 238, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/functional.py", line 2264, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
Expected all tensors to be on the same device, but found at least two devices, cuda:3 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)
  File "/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py", line 245, in <module>
    main()
  File "/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py", line 238, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/functional.py", line 2264, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
Expected all tensors to be on the same device, but found at least two devices, cuda:2 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)
  File "/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py", line 245, in <module>
    main()
  File "/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py", line 238, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/functional.py", line 2264, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)
  0%|          | 0/75 [00:00<?, ?it/s]
W0503 23:21:11.224887 47193197646784 torch/distributed/elastic/multiprocessing/api.py:851] Sending process 96846 closing signal SIGTERM
W0503 23:21:11.225241 47193197646784 torch/distributed/elastic/multiprocessing/api.py:851] Sending process 96848 closing signal SIGTERM
W0503 23:21:11.225318 47193197646784 torch/distributed/elastic/multiprocessing/api.py:851] Sending process 96849 closing signal SIGTERM
E0503 23:21:12.040069 47193197646784 torch/distributed/elastic/multiprocessing/api.py:826] failed (exitcode: 1) local_rank: 1 (pid: 96847) of binary: /share/home/zhangshanqi/pytorch/bin/python
Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/commands/accelerate_cli.py", line 48, in main
    args.func(args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/commands/launch.py", line 1153, in launch_command
    deepspeed_launcher(args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/commands/launch.py", line 846, in deepspeed_launcher
    distrib_run.run(args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/distributed/run.py", line 870, in run
    elastic_launch(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 263, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-05-03_23:21:11
  host      : gpu05
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 96847)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
W0504 13:28:03.097022 47868354057152 torch/distributed/run.py:757] 
W0504 13:28:03.097022 47868354057152 torch/distributed/run.py:757] *****************************************
W0504 13:28:03.097022 47868354057152 torch/distributed/run.py:757] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0504 13:28:03.097022 47868354057152 torch/distributed/run.py:757] *****************************************
Traceback (most recent call last):
  File "/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py", line 262, in <module>
Traceback (most recent call last):
  File "/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py", line 262, in <module>
Traceback (most recent call last):
  File "/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py", line 262, in <module>
Traceback (most recent call last):
  File "/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py", line 262, in <module>
            main()main()main()


  File "/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py", line 81, in main
  File "/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py", line 81, in main
  File "/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py", line 81, in main
    main()
  File "/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py", line 81, in main
    from transformers.modeling_utils import _get_submodules_from_module    
    from transformers.modeling_utils import _get_submodules_from_modulefrom transformers.modeling_utils import _get_submodules_from_module
ImportError
: ImportErrorcannot import name '_get_submodules_from_module' from 'transformers.modeling_utils' (/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py)ImportError    : 
: from transformers.modeling_utils import _get_submodules_from_modulecannot import name '_get_submodules_from_module' from 'transformers.modeling_utils' (/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py)cannot import name '_get_submodules_from_module' from 'transformers.modeling_utils' (/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py)


ImportError: cannot import name '_get_submodules_from_module' from 'transformers.modeling_utils' (/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py)
E0504 13:29:28.641474 47868354057152 torch/distributed/elastic/multiprocessing/api.py:826] failed (exitcode: 1) local_rank: 0 (pid: 25089) of binary: /share/home/zhangshanqi/pytorch/bin/python
Traceback (most recent call last):
  File "/share/home/zhangshanqi/pytorch/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/commands/accelerate_cli.py", line 48, in main
    args.func(args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/commands/launch.py", line 1153, in launch_command
    deepspeed_launcher(args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/commands/launch.py", line 846, in deepspeed_launcher
    distrib_run.run(args)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/distributed/run.py", line 870, in run
    elastic_launch(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 263, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/share/home/zhangshanqi/pyn/shopping_behavior2/models/pretrained/training_swanlab.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2025-05-04_13:29:28
  host      : gpu08
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 25090)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2025-05-04_13:29:28
  host      : gpu08
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 25091)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2025-05-04_13:29:28
  host      : gpu08
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 25092)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-05-04_13:29:28
  host      : gpu08
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 25089)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
  File "training_swanlab.py", line 93
  File "training_swanlab.py", line 93
        device_map[name] = "cpu""""
device_map[name] = "cpu""""
        ^
^
SyntaxErrorSyntaxError: : EOL while scanning string literalEOL while scanning string literal

  File "training_swanlab.py", line 93
    device_map[name] = "cpu""""
    ^
  File "training_swanlab.py", line 93
SyntaxError    : device_map[name] = "cpu""""
EOL while scanning string literal    
^
SyntaxError: EOL while scanning string literal
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [04:08<04:08, 248.05s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:08<04:08, 248.67s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:08<04:08, 248.69s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:08<04:08, 248.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:49<00:00, 232.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:49<00:00, 234.59s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Loading checkpoint shards: 100%|██████████| 2/2 [07:49<00:00, 232.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:49<00:00, 234.85s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [07:49<00:00, 232.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:49<00:00, 234.86s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Some parameters are on the meta device because they were offloaded to the cpu.
Loading checkpoint shards: 100%|██████████| 2/2 [07:49<00:00, 232.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:49<00:00, 234.94s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Traceback (most recent call last):
  File "training_swanlab.py", line 253, in <module>
    main()
  File "training_swanlab.py", line 115, in main
    model.get_input_embeddings().to(device)
NameError: name 'device' is not defined
Traceback (most recent call last):
  File "training_swanlab.py", line 253, in <module>
    main()
  File "training_swanlab.py", line 115, in main
    model.get_input_embeddings().to(device)
NameError: name 'device' is not defined
Traceback (most recent call last):
  File "training_swanlab.py", line 253, in <module>
    main()
  File "training_swanlab.py", line 115, in main
    model.get_input_embeddings().to(device)
NameError: name 'device' is not defined
Traceback (most recent call last):
  File "training_swanlab.py", line 253, in <module>
    main()
  File "training_swanlab.py", line 115, in main
    model.get_input_embeddings().to(device)
NameError: name 'device' is not defined
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [04:03<04:03, 243.51s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:04<04:04, 244.04s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:04<04:04, 244.08s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:04<04:04, 244.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:35<00:00, 225.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:35<00:00, 227.93s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Loading checkpoint shards: 100%|██████████| 2/2 [07:36<00:00, 225.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:36<00:00, 228.09s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Loading checkpoint shards: 100%|██████████| 2/2 [07:36<00:00, 225.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:36<00:00, 228.13s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Loading checkpoint shards: 100%|██████████| 2/2 [07:36<00:00, 225.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:36<00:00, 228.20s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 1/232 [00:00<00:58,  3.97 examples/s]Map:   0%|          | 1/232 [00:00<00:58,  3.97 examples/s]Map:   0%|          | 1/232 [00:00<00:58,  3.97 examples/s]Map:   0%|          | 1/232 [00:00<00:57,  4.00 examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 837.54 examples/s]                                                              Map: 100%|██████████| 232/232 [00:00<00:00, 831.72 examples/s]Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                              Map:   0%|          | 0/26 [00:00<?, ? examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 826.36 examples/s]                                                              Map:   0%|          | 0/26 [00:00<?, ? examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 822.95 examples/s]                                                              Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                                                                                                                                                                        Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.06 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 14.99 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.04 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 14.93 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:03<00:03, 34.86 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 34.31 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 33.77 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 33.52 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:00, 59.80 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 57.23 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 56.00 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 54.98 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 84.16 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 85.35 examples/s]                                                                          Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 82.93 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 79.48 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
                                                                          /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
                                                                                                                                                    /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.76 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:04,  4.73 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.78 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01,  9.96 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:04,  4.66 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01,  9.84 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01,  9.91 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.12 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01,  9.54 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.09 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.09 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:02<00:00, 17.83 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 13.17 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:02<00:00, 17.60 examples/s]                                                                        Map (num_proc=4): 100%|██████████| 26/26 [00:02<00:00, 17.46 examples/s]                                                                        /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
                                                                        Map (num_proc=4): 100%|██████████| 26/26 [00:02<00:00, 16.28 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
                                                                        /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
training_swanlab.py:243: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:236: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:243: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:236: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:243: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:236: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:243: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:236: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121/cpu_adam/build.ninja...
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Loading extension module cpu_adam...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  0%|          | 0/75 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  File "training_swanlab.py", line 253, in <module>
    main()
  File "training_swanlab.py", line 246, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/functional.py", line 2264, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
Expected all tensors to be on the same device, but found at least two devices, cuda:2 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)
  File "training_swanlab.py", line 253, in <module>
    main()
  File "training_swanlab.py", line 246, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/functional.py", line 2264, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)
  File "training_swanlab.py", line 253, in <module>
    main()
  File "training_swanlab.py", line 246, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/functional.py", line 2264, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
Expected all tensors to be on the same device, but found at least two devices, cuda:3 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)
  File "training_swanlab.py", line 253, in <module>
    main()
  File "training_swanlab.py", line 246, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/functional.py", line 2264, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)
  0%|          | 0/75 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [04:42<04:42, 282.09s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:42<04:42, 282.64s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:42<04:42, 282.68s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:42<04:42, 282.72s/it]Loading checkpoint shards:  50%|█████     | 1/2 [07:16<07:16, 436.67s/it]Loading checkpoint shards:  50%|█████     | 1/2 [07:16<07:16, 436.67s/it]Loading checkpoint shards:  50%|█████     | 1/2 [07:16<07:16, 436.68s/it]


Loading checkpoint shards:  50%|█████     | 1/2 [07:16<07:16, 436.66s/it]Traceback (most recent call last):

  File "training_swanlab.py", line 256, in <module>
Traceback (most recent call last):
Traceback (most recent call last):
  File "training_swanlab.py", line 256, in <module>
  File "training_swanlab.py", line 256, in <module>
Traceback (most recent call last):
  File "training_swanlab.py", line 256, in <module>
    main()
  File "training_swanlab.py", line 92, in main
        main()main()
    
  File "training_swanlab.py", line 92, in main
main()  File "training_swanlab.py", line 92, in main

  File "training_swanlab.py", line 92, in main
    model = AutoModelForCausalLM.from_pretrained(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
    model = AutoModelForCausalLM.from_pretrained(
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
model = AutoModelForCausalLM.from_pretrained(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
    model = AutoModelForCausalLM.from_pretrained(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
            return model_class.from_pretrained(return model_class.from_pretrained(    return model_class.from_pretrained(

return model_class.from_pretrained(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4225, in from_pretrained
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4225, in from_pretrained

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4225, in from_pretrained
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4225, in from_pretrained
    ) = cls._load_pretrained_model(    
) = cls._load_pretrained_model(  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4728, in _load_pretrained_model

      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4728, in _load_pretrained_model
) = cls._load_pretrained_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4728, in _load_pretrained_model
    ) = cls._load_pretrained_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4728, in _load_pretrained_model
    new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 995, in _load_state_dict_into_meta_model
    new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 995, in _load_state_dict_into_meta_model
    new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 995, in _load_state_dict_into_meta_model
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 995, in _load_state_dict_into_meta_model
    hf_quantizer.create_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/quantizers/quantizer_bnb_8bit.py", line 226, in create_quantized_param
    hf_quantizer.create_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/quantizers/quantizer_bnb_8bit.py", line 226, in create_quantized_param
hf_quantizer.create_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/quantizers/quantizer_bnb_8bit.py", line 226, in create_quantized_param
hf_quantizer.create_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/quantizers/quantizer_bnb_8bit.py", line 226, in create_quantized_param
    new_value = bnb.nn.Int8Params(new_value, requires_grad=False, **kwargs).to(target_device)    
    new_value = bnb.nn.Int8Params(new_value, requires_grad=False, **kwargs).to(target_device)      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 342, in to
new_value = bnb.nn.Int8Params(new_value, requires_grad=False, **kwargs).to(target_device)
new_value = bnb.nn.Int8Params(new_value, requires_grad=False, **kwargs).to(target_device)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 342, in to

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 342, in to
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 342, in to
    return self.cuda(device)    
        return self.cuda(device)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 306, in cuda
return self.cuda(device)return self.cuda(device)


  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 306, in cuda
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 306, in cuda
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/nn/modules.py", line 306, in cuda
    CB, CBt, SCB, SCBt, coo_tensorB = bnb.functional.double_quant(B)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/functional.py", line 2121, in double_quant
    CB, CBt, SCB, SCBt, coo_tensorB = bnb.functional.double_quant(B)
      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/functional.py", line 2121, in double_quant
    CB, CBt, SCB, SCBt, coo_tensorB = bnb.functional.double_quant(B)CB, CBt, SCB, SCBt, coo_tensorB = bnb.functional.double_quant(B)

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/functional.py", line 2121, in double_quant
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/bitsandbytes/functional.py", line 2121, in double_quant
        out_row = torch.zeros(A.shape, device=device, dtype=torch.int8)    out_row = torch.zeros(A.shape, device=device, dtype=torch.int8)
out_row = torch.zeros(A.shape, device=device, dtype=torch.int8)

    torch.cudaout_row = torch.zeros(A.shape, device=device, dtype=torch.int8)torch.cuda.
.torch.cudaOutOfMemoryErrorOutOfMemoryError.torch.cuda: : OutOfMemoryError.CUDA out of memory. Tried to allocate 56.00 MiB. GPU CUDA out of memory. Tried to allocate 56.00 MiB. GPU : OutOfMemoryError

CUDA out of memory. Tried to allocate 56.00 MiB. GPU : 
CUDA out of memory. Tried to allocate 56.00 MiB. GPU 
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [04:03<04:03, 243.78s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:04<04:04, 244.16s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:04<04:04, 244.16s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:04<04:04, 244.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:31<00:00, 222.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:31<00:00, 225.83s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Loading checkpoint shards: 100%|██████████| 2/2 [07:32<00:00, 222.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:32<00:00, 226.08s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [07:32<00:00, 222.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:32<00:00, 226.09s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [07:32<00:00, 222.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:32<00:00, 226.08s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Some parameters are on the meta device because they were offloaded to the cpu.
Some parameters are on the meta device because they were offloaded to the cpu.
Traceback (most recent call last):
  File "training_swanlab.py", line 256, in <module>
Traceback (most recent call last):
  File "training_swanlab.py", line 256, in <module>
Traceback (most recent call last):
  File "training_swanlab.py", line 256, in <module>
Traceback (most recent call last):
  File "training_swanlab.py", line 256, in <module>
    main()        
    main()main()  File "training_swanlab.py", line 113, in main
main()


  File "training_swanlab.py", line 113, in main
  File "training_swanlab.py", line 113, in main
  File "training_swanlab.py", line 113, in main
    model = dispatch_model(model, device_map="auto")
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/big_modeling.py", line 352, in dispatch_model
        model = dispatch_model(model, device_map="auto")    model = dispatch_model(model, device_map="auto")
model = dispatch_model(model, device_map="auto")
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/big_modeling.py", line 352, in dispatch_model

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/big_modeling.py", line 352, in dispatch_model
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/big_modeling.py", line 352, in dispatch_model
        check_device_map(model, device_map)    check_device_map(model, device_map)    
check_device_map(model, device_map)
check_device_map(model, device_map)  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/utils/modeling.py", line 1408, in check_device_map

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/utils/modeling.py", line 1408, in check_device_map

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/utils/modeling.py", line 1408, in check_device_map
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/utils/modeling.py", line 1408, in check_device_map
    for module_name in device_map.keys():    
for module_name in device_map.keys():        
AttributeErrorfor module_name in device_map.keys():for module_name in device_map.keys():: AttributeError

'str' object has no attribute 'keys': 
AttributeError'str' object has no attribute 'keys'AttributeError: 
: 'str' object has no attribute 'keys''str' object has no attribute 'keys'

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [04:03<04:03, 243.14s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:03<04:03, 243.58s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:03<04:03, 243.61s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:03<04:03, 243.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:35<00:00, 225.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:35<00:00, 227.83s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Loading checkpoint shards: 100%|██████████| 2/2 [07:36<00:00, 225.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:36<00:00, 228.01s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [07:35<00:00, 225.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:35<00:00, 228.00s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [07:36<00:00, 225.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:36<00:00, 228.03s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Some parameters are on the meta device because they were offloaded to the cpu.
Some parameters are on the meta device because they were offloaded to the cpu.
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 1/232 [00:00<01:15,  3.06 examples/s]Map:  91%|█████████▏| 212/232 [00:00<00:00, 636.16 examples/s]                                                              Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                  Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 2004.21 examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                  Map: 100%|██████████| 232/232 [00:00<00:00, 2020.03 examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 2180.84 examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                                                                    Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.04 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.37 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 34.51 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.20 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.39 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 33.72 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 56.52 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 33.51 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 34.29 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 85.15 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 55.37 examples/s]                                                                          Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 56.74 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 54.34 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 86.22 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 80.42 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 79.85 examples/s]                                                                                                                                                    /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
                                                                          /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.85 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01,  9.55 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.78 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 13.85 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:04,  4.67 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.02 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:04,  4.57 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 18.26 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01,  9.55 examples/s]                                                                        Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.07 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01,  9.50 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 13.17 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:02<00:00, 17.81 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 13.11 examples/s]                                                                        /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
Map (num_proc=4): 100%|██████████| 26/26 [00:02<00:00, 16.35 examples/s]                                                                        Map (num_proc=4): 100%|██████████| 26/26 [00:02<00:00, 15.98 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
                                                                        /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[rank0]: Traceback (most recent call last):
[rank0]:   File "training_swanlab.py", line 256, in <module>
[rank0]:     main()
[rank0]:   File "training_swanlab.py", line 209, in main
[rank0]:     training_args = TrainingArguments(
[rank0]:   File "<string>", line 134, in __init__
[rank0]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py", line 2032, in __post_init__
[rank0]:     self.hf_deepspeed_config = HfTrainerDeepSpeedConfig(self.deepspeed)
[rank0]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/integrations/deepspeed.py", line 91, in __init__
[rank0]:     super().__init__(config_file_or_dict)
[rank0]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/integrations/deepspeed.py", line 81, in __init__
[rank0]:     super().__init__(config_file_or_dict)
[rank0]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/utils/deepspeed.py", line 68, in __init__
[rank0]:     config = json.load(f)
[rank0]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/__init__.py", line 293, in load
[rank0]:     return loads(fp.read(),
[rank0]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/__init__.py", line 357, in loads
[rank0]:     return _default_decoder.decode(s)
[rank0]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/decoder.py", line 337, in decode
[rank0]:     obj, end = self.raw_decode(s, idx=_w(s, 0).end())
[rank0]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/decoder.py", line 355, in raw_decode
[rank0]:     raise JSONDecodeError("Expecting value", s, err.value) from None
[rank0]: json.decoder.JSONDecodeError: Expecting value: line 18 column 21 (char 359)
[rank1]: Traceback (most recent call last):
[rank1]:   File "training_swanlab.py", line 256, in <module>
[rank1]:     main()
[rank1]:   File "training_swanlab.py", line 209, in main
[rank1]:     training_args = TrainingArguments(
[rank1]:   File "<string>", line 134, in __init__
[rank1]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py", line 2032, in __post_init__
[rank1]:     self.hf_deepspeed_config = HfTrainerDeepSpeedConfig(self.deepspeed)
[rank1]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/integrations/deepspeed.py", line 91, in __init__
[rank1]:     super().__init__(config_file_or_dict)
[rank1]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/integrations/deepspeed.py", line 81, in __init__
[rank1]:     super().__init__(config_file_or_dict)
[rank1]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/utils/deepspeed.py", line 68, in __init__
[rank1]:     config = json.load(f)
[rank1]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/__init__.py", line 293, in load
[rank1]:     return loads(fp.read(),
[rank1]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/__init__.py", line 357, in loads
[rank1]:     return _default_decoder.decode(s)
[rank1]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/decoder.py", line 337, in decode
[rank1]:     obj, end = self.raw_decode(s, idx=_w(s, 0).end())
[rank1]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/decoder.py", line 355, in raw_decode
[rank1]:     raise JSONDecodeError("Expecting value", s, err.value) from None
[rank1]: json.decoder.JSONDecodeError: Expecting value: line 18 column 21 (char 359)
[rank3]: Traceback (most recent call last):
[rank3]:   File "training_swanlab.py", line 256, in <module>
[rank3]:     main()
[rank3]:   File "training_swanlab.py", line 209, in main
[rank3]:     training_args = TrainingArguments(
[rank3]:   File "<string>", line 134, in __init__
[rank3]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py", line 2032, in __post_init__
[rank3]:     self.hf_deepspeed_config = HfTrainerDeepSpeedConfig(self.deepspeed)
[rank3]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/integrations/deepspeed.py", line 91, in __init__
[rank3]:     super().__init__(config_file_or_dict)
[rank3]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/integrations/deepspeed.py", line 81, in __init__
[rank3]:     super().__init__(config_file_or_dict)
[rank3]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/utils/deepspeed.py", line 68, in __init__
[rank3]:     config = json.load(f)
[rank3]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/__init__.py", line 293, in load
[rank3]:     return loads(fp.read(),
[rank3]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/__init__.py", line 357, in loads
[rank3]:     return _default_decoder.decode(s)
[rank3]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/decoder.py", line 337, in decode
[rank3]:     obj, end = self.raw_decode(s, idx=_w(s, 0).end())
[rank3]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/decoder.py", line 355, in raw_decode
[rank3]:     raise JSONDecodeError("Expecting value", s, err.value) from None
[rank3]: json.decoder.JSONDecodeError: Expecting value: line 18 column 21 (char 359)
[rank2]: Traceback (most recent call last):
[rank2]:   File "training_swanlab.py", line 256, in <module>
[rank2]:     main()
[rank2]:   File "training_swanlab.py", line 209, in main
[rank2]:     training_args = TrainingArguments(
[rank2]:   File "<string>", line 134, in __init__
[rank2]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py", line 2032, in __post_init__
[rank2]:     self.hf_deepspeed_config = HfTrainerDeepSpeedConfig(self.deepspeed)
[rank2]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/integrations/deepspeed.py", line 91, in __init__
[rank2]:     super().__init__(config_file_or_dict)
[rank2]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/integrations/deepspeed.py", line 81, in __init__
[rank2]:     super().__init__(config_file_or_dict)
[rank2]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/utils/deepspeed.py", line 68, in __init__
[rank2]:     config = json.load(f)
[rank2]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/__init__.py", line 293, in load
[rank2]:     return loads(fp.read(),
[rank2]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/__init__.py", line 357, in loads
[rank2]:     return _default_decoder.decode(s)
[rank2]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/decoder.py", line 337, in decode
[rank2]:     obj, end = self.raw_decode(s, idx=_w(s, 0).end())
[rank2]:   File "/share/home/zhangshanqi/pytorch/lib/python3.8/json/decoder.py", line 355, in raw_decode
[rank2]:     raise JSONDecodeError("Expecting value", s, err.value) from None
[rank2]: json.decoder.JSONDecodeError: Expecting value: line 18 column 21 (char 359)
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [02:56<02:56, 176.42s/it]Loading checkpoint shards:  50%|█████     | 1/2 [02:56<02:56, 176.87s/it]Loading checkpoint shards:  50%|█████     | 1/2 [02:56<02:56, 176.88s/it]Loading checkpoint shards:  50%|█████     | 1/2 [02:56<02:56, 176.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [05:48<00:00, 173.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [05:48<00:00, 174.23s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Loading checkpoint shards: 100%|██████████| 2/2 [05:48<00:00, 174.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [05:48<00:00, 174.39s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [05:48<00:00, 173.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [05:48<00:00, 174.40s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Some parameters are on the meta device because they were offloaded to the cpu.
Loading checkpoint shards: 100%|██████████| 2/2 [05:48<00:00, 174.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [05:48<00:00, 174.46s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 1/232 [00:00<01:09,  3.32 examples/s]Map:   0%|          | 1/232 [00:00<01:09,  3.32 examples/s]Map:   0%|          | 1/232 [00:00<01:09,  3.32 examples/s]Map:   0%|          | 1/232 [00:00<01:09,  3.32 examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 739.25 examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 738.32 examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 739.58 examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 737.71 examples/s]                                                                                                                                                                                                                                                        Map:   0%|          | 0/26 [00:00<?, ? examples/s]Map:   0%|          | 0/26 [00:00<?, ? examples/s]Map:   0%|          | 0/26 [00:00<?, ? examples/s]Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                                                                                                                                                                        Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.10 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.06 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.05 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.10 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 34.26 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 34.12 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 34.15 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 32.79 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 57.28 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 57.23 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 56.38 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 55.45 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 84.78 examples/s]                                                                          Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 80.86 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 74.31 examples/s]                                                                          /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
                                                                          Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 69.96 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
                                                                          /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:04,  4.68 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.31 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  5.01 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.77 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.71 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01,  9.86 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.86 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01,  9.17 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.31 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 17.59 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 13.75 examples/s]                                                                        Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 12.91 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.70 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
Map (num_proc=4): 100%|██████████| 26/26 [00:02<00:00, 16.98 examples/s]                                                                                                                                                Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 18.32 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
                                                                        /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
training_swanlab.py:246: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:246: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:239: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:239: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:246: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:239: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:246: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:239: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121/cpu_adam/build.ninja...
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Loading extension module cpu_adam...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  0%|          | 0/15 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  File "training_swanlab.py", line 256, in <module>
    main()
  File "training_swanlab.py", line 249, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/functional.py", line 2264, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)
  File "training_swanlab.py", line 256, in <module>
    main()
  File "training_swanlab.py", line 249, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/functional.py", line 2264, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
Expected all tensors to be on the same device, but found at least two devices, cuda:2 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)
  File "training_swanlab.py", line 256, in <module>
    main()
  File "training_swanlab.py", line 249, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/functional.py", line 2264, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)
  File "training_swanlab.py", line 256, in <module>
    main()
  File "training_swanlab.py", line 249, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/functional.py", line 2264, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
Expected all tensors to be on the same device, but found at least two devices, cuda:3 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)
  0%|          | 0/15 [00:01<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [04:10<04:10, 250.16s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:10<04:10, 250.64s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:10<04:10, 250.69s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:10<04:10, 250.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:46<00:00, 230.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:46<00:00, 233.19s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Loading checkpoint shards: 100%|██████████| 2/2 [07:46<00:00, 230.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:46<00:00, 233.44s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [07:46<00:00, 230.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:46<00:00, 233.44s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Some parameters are on the meta device because they were offloaded to the cpu.
Loading checkpoint shards: 100%|██████████| 2/2 [07:47<00:00, 230.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:47<00:00, 233.51s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 1390.64 examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                  Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 2194.71 examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                  Map: 100%|██████████| 232/232 [00:00<00:00, 2147.39 examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                  Map: 100%|██████████| 232/232 [00:00<00:00, 2055.29 examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                  Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 14.99 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 33.91 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:00, 58.61 examples/s]                                                                          /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.79 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:03<00:03, 34.95 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 14.78 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 14.87 examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 55.29 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 57.16 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 86.61 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 49.86 examples/s]                                                                                                                                                    /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
                                                                          /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.77 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01,  9.60 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 13.40 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:02<00:00, 16.96 examples/s]                                                                        Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.82 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:04,  4.73 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.83 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.00 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01,  9.89 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.00 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.24 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 13.69 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 13.83 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 17.98 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:02<00:00, 16.79 examples/s]                                                                        /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
                                                                        Map (num_proc=4): 100%|██████████| 26/26 [00:02<00:00, 15.88 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
                                                                        /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
training_swanlab.py:259: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:252: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:259: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:252: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:259: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:252: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:259: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:252: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...

Detected CUDA files, patching ldflags
Emitting ninja build file /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121/cpu_adam/build.ninja...
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Loading extension module cpu_adam...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  0%|          | 0/15 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  File "training_swanlab.py", line 269, in <module>
    main()
  File "training_swanlab.py", line 262, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "training_swanlab.py", line 10, in _patched_embed_forward
    self.weight = self.weight.to(input.device)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1729, in __setattr__
    raise TypeError(f"cannot assign '{torch.typename(value)}' as parameter '{name}' "
cannot assign 'torch.HalfTensor' as parameter 'weight' (torch.nn.Parameter or None expected)
  File "training_swanlab.py", line 269, in <module>
    main()
  File "training_swanlab.py", line 262, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "training_swanlab.py", line 10, in _patched_embed_forward
    self.weight = self.weight.to(input.device)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1729, in __setattr__
    raise TypeError(f"cannot assign '{torch.typename(value)}' as parameter '{name}' "
cannot assign 'torch.HalfTensor' as parameter 'weight' (torch.nn.Parameter or None expected)
  File "training_swanlab.py", line 269, in <module>
    main()
  File "training_swanlab.py", line 262, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "training_swanlab.py", line 10, in _patched_embed_forward
    self.weight = self.weight.to(input.device)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1729, in __setattr__
    raise TypeError(f"cannot assign '{torch.typename(value)}' as parameter '{name}' "
cannot assign 'torch.HalfTensor' as parameter 'weight' (torch.nn.Parameter or None expected)
  File "training_swanlab.py", line 269, in <module>
    main()
  File "training_swanlab.py", line 262, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "training_swanlab.py", line 10, in _patched_embed_forward
    self.weight = self.weight.to(input.device)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1729, in __setattr__
    raise TypeError(f"cannot assign '{torch.typename(value)}' as parameter '{name}' "
cannot assign 'torch.HalfTensor' as parameter 'weight' (torch.nn.Parameter or None expected)
  0%|          | 0/15 [00:01<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [04:01<04:01, 241.61s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:02<04:02, 242.13s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:02<04:02, 242.16s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:02<04:02, 242.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:45<00:00, 230.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:45<00:00, 232.52s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Loading checkpoint shards: 100%|██████████| 2/2 [07:45<00:00, 231.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:45<00:00, 232.73s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [07:45<00:00, 231.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:45<00:00, 232.74s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [07:45<00:00, 231.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:45<00:00, 232.75s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Some parameters are on the meta device because they were offloaded to the cpu.
Some parameters are on the meta device because they were offloaded to the cpu.
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 1/232 [00:00<01:22,  2.82 examples/s]Map:  72%|███████▏  | 168/232 [00:00<00:00, 444.58 examples/s]                                                              Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                  Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 2189.76 examples/s]                                                               Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                  Map: 100%|██████████| 232/232 [00:00<00:00, 2217.16 examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 2090.68 examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                                                                    Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.65 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.66 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.80 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.19 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:03<00:03, 35.16 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:03<00:01, 54.27 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 33.45 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 56.91 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 72.96 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 49.77 examples/s]                                                                          Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 83.14 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 53.56 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
                                                                                                                                                    /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 78.23 examples/s]                                                                          /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.86 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.93 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.13 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.78 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.43 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01,  9.97 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 13.36 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:04,  4.69 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 18.28 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.18 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 17.43 examples/s]                                                                                                                                                /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01,  9.30 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 17.90 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
                                                                        Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 13.71 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
Map (num_proc=4): 100%|██████████| 26/26 [00:02<00:00, 16.33 examples/s]                                                                        /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
training_swanlab.py:256: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:249: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:256: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:249: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:256: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:249: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:256: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:249: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121/cpu_adam/build.ninja...
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Loading extension module cpu_adam...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  0%|          | 0/15 [00:00<?, ?it/s]  File "training_swanlab.py", line 266, in <module>
    main()
  File "training_swanlab.py", line 259, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
_patched_F_embedding() takes from 2 to 5 positional arguments but 7 were given  File "training_swanlab.py", line 266, in <module>
    main()
  File "training_swanlab.py", line 259, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
_patched_F_embedding() takes from 2 to 5 positional arguments but 7 were given

  File "training_swanlab.py", line 266, in <module>
    main()
  File "training_swanlab.py", line 259, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
_patched_F_embedding() takes from 2 to 5 positional arguments but 7 were given
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  File "training_swanlab.py", line 266, in <module>
    main()
  File "training_swanlab.py", line 259, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 891, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
_patched_F_embedding() takes from 2 to 5 positional arguments but 7 were given
  0%|          | 0/15 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [03:51<03:51, 231.54s/it]Loading checkpoint shards:  50%|█████     | 1/2 [03:52<03:52, 232.06s/it]Loading checkpoint shards:  50%|█████     | 1/2 [03:52<03:52, 232.06s/it]Loading checkpoint shards:  50%|█████     | 1/2 [03:52<03:52, 232.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:41<00:00, 230.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:41<00:00, 230.92s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Loading checkpoint shards: 100%|██████████| 2/2 [07:42<00:00, 231.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:42<00:00, 231.17s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [07:42<00:00, 230.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:42<00:00, 231.15s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Some parameters are on the meta device because they were offloaded to the cpu.
Loading checkpoint shards: 100%|██████████| 2/2 [07:42<00:00, 231.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:42<00:00, 231.25s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 1/232 [00:00<01:37,  2.37 examples/s]Map:   0%|          | 1/232 [00:00<01:43,  2.24 examples/s]Map:   0%|          | 1/232 [00:00<01:37,  2.36 examples/s]Map:   0%|          | 1/232 [00:00<03:12,  1.20 examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 584.03 examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 583.34 examples/s]                                                                                                                            Map: 100%|██████████| 232/232 [00:00<00:00, 557.69 examples/s]Map:   0%|          | 0/26 [00:00<?, ? examples/s]Map:   0%|          | 0/26 [00:00<?, ? examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 334.54 examples/s]                                                                                                                            Map:   0%|          | 0/26 [00:00<?, ? examples/s]Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                                                                                                                                                                        Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.77 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.48 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.07 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:03<00:03, 35.40 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 14.66 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 33.71 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 33.85 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 57.86 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 32.80 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 55.96 examples/s]                                                                          Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 85.42 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 54.46 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 86.38 examples/s]                                                                          /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
                                                                          /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 67.90 examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]                                                                          /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.93 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:04,  4.54 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.79 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.26 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.50 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01,  9.30 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 12.91 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.25 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 18.25 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 16.89 examples/s]                                                                                                                                                Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:04,  4.70 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
Map (num_proc=4): 100%|██████████| 26/26 [00:02<00:00, 17.15 examples/s]                                                                        Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01,  9.62 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 13.17 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:02<00:00, 16.23 examples/s]                                                                        /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
training_swanlab.py:274: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:267: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:274: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:267: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:274: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:274: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:267: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:267: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121/cpu_adam/build.ninja...
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Loading extension module cpu_adam...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  0%|          | 0/15 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  File "training_swanlab.py", line 284, in <module>
    main()
  File "training_swanlab.py", line 277, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 921, in forward
    position_embeddings = self.rotary_emb(hidden_states, position_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 158, in forward
    freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)
Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat2 in method wrapper_CUDA_bmm)
  File "training_swanlab.py", line 284, in <module>
    main()
  File "training_swanlab.py", line 277, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 921, in forward
    position_embeddings = self.rotary_emb(hidden_states, position_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 158, in forward
    freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)
Expected all tensors to be on the same device, but found at least two devices, cuda:2 and cpu! (when checking argument for argument mat2 in method wrapper_CUDA_bmm)
  File "training_swanlab.py", line 284, in <module>
    main()
  File "training_swanlab.py", line 277, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 921, in forward
    position_embeddings = self.rotary_emb(hidden_states, position_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 158, in forward
    freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)
Expected all tensors to be on the same device, but found at least two devices, cuda:3 and cpu! (when checking argument for argument mat2 in method wrapper_CUDA_bmm)
  File "training_swanlab.py", line 284, in <module>
    main()
  File "training_swanlab.py", line 277, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 921, in forward
    position_embeddings = self.rotary_emb(hidden_states, position_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 158, in forward
    freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)
Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cpu! (when checking argument for argument mat2 in method wrapper_CUDA_bmm)
  0%|          | 0/15 [00:01<?, ?it/s]
Traceback (most recent call last):
Traceback (most recent call last):
  File "training_swanlab.py", line 307, in <module>
  File "training_swanlab.py", line 307, in <module>
Traceback (most recent call last):
  File "training_swanlab.py", line 307, in <module>
Traceback (most recent call last):
  File "training_swanlab.py", line 307, in <module>
    main()
  File "training_swanlab.py", line 143, in main
        main()    main()
main()
  File "training_swanlab.py", line 143, in main

  File "training_swanlab.py", line 143, in main
  File "training_swanlab.py", line 143, in main
    model = AutoModelForCausalLM.from_pretrained(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
    model = AutoModelForCausalLM.from_pretrained(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
        model = AutoModelForCausalLM.from_pretrained(model = AutoModelForCausalLM.from_pretrained(

  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
          File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 3657, in from_pretrained
    return model_class.from_pretrained(return model_class.from_pretrained(return model_class.from_pretrained(


  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 3657, in from_pretrained
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 3657, in from_pretrained
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/modeling_utils.py", line 3657, in from_pretrained
        hf_quantizer.validate_environment(    hf_quantizer.validate_environment(
hf_quantizer.validate_environment(

      File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/quantizers/quantizer_bnb_8bit.py", line 73, in validate_environment
hf_quantizer.validate_environment(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/quantizers/quantizer_bnb_8bit.py", line 73, in validate_environment
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/quantizers/quantizer_bnb_8bit.py", line 73, in validate_environment
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/quantizers/quantizer_bnb_8bit.py", line 73, in validate_environment
    raise ImportError(        
    raise ImportError(raise ImportError(raise ImportError(
ImportError

: ImportErrorImportErrorUsing `bitsandbytes` 8-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`ImportError: : 
: Using `bitsandbytes` 8-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`Using `bitsandbytes` 8-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`Using `bitsandbytes` 8-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`


Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [04:06<04:06, 246.55s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:07<04:07, 247.02s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:07<04:07, 247.10s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:07<04:07, 247.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:35<00:00, 224.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:35<00:00, 227.73s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Loading checkpoint shards: 100%|██████████| 2/2 [07:35<00:00, 224.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:35<00:00, 227.98s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [07:35<00:00, 224.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:35<00:00, 228.00s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [07:36<00:00, 224.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:36<00:00, 228.00s/it]
Some parameters are on the meta device because they were offloaded to the cpu.
Some parameters are on the meta device because they were offloaded to the cpu.
Some parameters are on the meta device because they were offloaded to the cpu.
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 1/232 [00:00<00:37,  6.09 examples/s]Map:  81%|████████▏ | 189/232 [00:00<00:00, 877.71 examples/s]                                                              Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                  Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 2168.55 examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 2220.90 examples/s]                                                                                                                              Map:   0%|          | 0/26 [00:00<?, ? examples/s]Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                                                                    Map: 100%|██████████| 232/232 [00:00<00:00, 2132.70 examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                  Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.05 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.19 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 14.87 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 15.13 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 34.38 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 33.60 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 33.21 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 33.44 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 56.34 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 55.08 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 55.09 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 54.74 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 84.59 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 83.27 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 83.21 examples/s]                                                                                                                                                                                                                              Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 80.65 examples/s]/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
                                                                          /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.84 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.80 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  4.78 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.08 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.01 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.10 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:04,  4.68 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.21 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.20 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.00 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01,  9.53 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 17.90 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 17.79 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 17.82 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 13.27 examples/s]                                                                                                                                                                                                                        /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
Map (num_proc=4): 100%|██████████| 26/26 [00:02<00:00, 16.40 examples/s]                                                                        /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
training_swanlab.py:297: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:290: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:297: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:290: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:297: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:290: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:297: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:290: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...Using /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121 as PyTorch extensions root...



Detected CUDA files, patching ldflags
Emitting ninja build file /share/home/zhangshanqi/.cache/torch_extensions/py38_cu121/cpu_adam/build.ninja...
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Loading extension module cpu_adam...Loading extension module cpu_adam...

`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  0%|          | 0/15 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  File "training_swanlab.py", line 307, in <module>
    main()
  File "training_swanlab.py", line 300, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 921, in forward
    position_embeddings = self.rotary_emb(hidden_states, position_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 158, in forward
    freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)
Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cpu! (when checking argument for argument mat2 in method wrapper_CUDA_bmm)
  File "training_swanlab.py", line 307, in <module>
    main()
  File "training_swanlab.py", line 300, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 921, in forward
    position_embeddings = self.rotary_emb(hidden_states, position_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 158, in forward
    freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)
Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat2 in method wrapper_CUDA_bmm)
  File "training_swanlab.py", line 307, in <module>
    main()
  File "training_swanlab.py", line 300, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 921, in forward
    position_embeddings = self.rotary_emb(hidden_states, position_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 158, in forward
    freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)
Expected all tensors to be on the same device, but found at least two devices, cuda:2 and cpu! (when checking argument for argument mat2 in method wrapper_CUDA_bmm)
  File "training_swanlab.py", line 307, in <module>
    main()
  File "training_swanlab.py", line 300, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 3633, in compute_loss
    outputs = model(**inputs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/deepspeed/runtime/engine.py", line 2054, in forward
    loss = self.module(*inputs, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/peft_model.py", line 1644, in forward
    return self.base_model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1190, in forward
    outputs = self.model(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/hooks.py", line 170, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 921, in forward
    position_embeddings = self.rotary_emb(hidden_states, position_ids)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1582, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 158, in forward
    freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)
Expected all tensors to be on the same device, but found at least two devices, cuda:3 and cpu! (when checking argument for argument mat2 in method wrapper_CUDA_bmm)
  0%|          | 0/15 [00:02<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [04:01<04:01, 241.45s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:01<04:01, 241.92s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:02<04:02, 242.02s/it]Loading checkpoint shards:  50%|█████     | 1/2 [04:02<04:02, 242.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:45<00:00, 231.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:45<00:00, 232.76s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [07:45<00:00, 231.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:45<00:00, 232.90s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [07:45<00:00, 231.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:45<00:00, 232.94s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [07:45<00:00, 231.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [07:45<00:00, 232.97s/it]
Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 0/232 [00:00<?, ? examples/s]Map:   0%|          | 1/232 [00:00<00:29,  7.93 examples/s]Map:   0%|          | 1/232 [00:00<00:28,  8.05 examples/s]Map:   0%|          | 1/232 [00:00<00:27,  8.36 examples/s]Map:   0%|          | 1/232 [00:00<00:58,  3.97 examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 823.40 examples/s]Map: 100%|██████████| 232/232 [00:00<00:00, 1194.84 examples/s]                                                              Map: 100%|██████████| 232/232 [00:00<00:00, 1219.35 examples/s]                                                               Map: 100%|██████████| 232/232 [00:00<00:00, 1194.30 examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                               Map:   0%|          | 0/26 [00:00<?, ? examples/s]Map:   0%|          | 0/26 [00:00<?, ? examples/s]                                                                                                                                                                                                        Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/232 [00:00<?, ? examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 14.99 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 14.99 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 14.99 examples/s]Map (num_proc=4):  25%|██▌       | 58/232 [00:03<00:11, 14.95 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 34.62 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 34.54 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 34.45 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 57.04 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 57.00 examples/s]Map (num_proc=4):  75%|███████▌  | 174/232 [00:04<00:01, 56.81 examples/s]Map (num_proc=4):  50%|█████     | 116/232 [00:04<00:03, 31.57 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 86.35 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 84.85 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 83.43 examples/s]Map (num_proc=4): 100%|██████████| 232/232 [00:04<00:00, 78.89 examples/s]                                                                          /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
                                                                                                                                                                                                                              /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1381: FutureWarning: promote has been superseded by promote_options='default'.
  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/datasets/table.py:1407: FutureWarning: promote has been superseded by promote_options='default'.
  table = cls._concat_blocks(blocks, axis=0)
Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):   0%|          | 0/26 [00:00<?, ? examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  5.02 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  5.04 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  5.05 examples/s]Map (num_proc=4):  27%|██▋       | 7/26 [00:01<00:03,  5.01 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.41 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.39 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01, 10.51 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.78 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.66 examples/s]Map (num_proc=4):  54%|█████▍    | 14/26 [00:01<00:01,  9.08 examples/s]Map (num_proc=4):  77%|███████▋  | 20/26 [00:01<00:00, 14.71 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 18.21 examples/s]Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 18.33 examples/s]                                                                        Map (num_proc=4): 100%|██████████| 26/26 [00:01<00:00, 18.42 examples/s]                                                                                                                                                /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
Map (num_proc=4): 100%|██████████| 26/26 [00:02<00:00, 15.48 examples/s]                                                                        /share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
training_swanlab.py:247: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:240: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:247: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:240: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:247: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:240: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
training_swanlab.py:247: FutureWarning: `swanlab.integration.huggingface.SwanLabCallback` is deprecated. Please use `swanlab.integration.transformers.SwanLabCallback` instead.
  callbacks=[SwanLabCallback()]
training_swanlab.py:240: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  File "training_swanlab.py", line 257, in <module>
    main()
  File "training_swanlab.py", line 250, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2275, in _inner_training_loop
    model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/accelerator.py", line 1300, in prepare
    raise ValueError(
You can't train a model that has been loaded with `device_map='auto'` in any distributed mode. Please rerun your script specifying `--num_processes=1` or by launching with `python {{myscript.py}}`.
  File "training_swanlab.py", line 257, in <module>
    main()
  File "training_swanlab.py", line 250, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2275, in _inner_training_loop
    model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/accelerator.py", line 1300, in prepare
    raise ValueError(
You can't train a model that has been loaded with `device_map='auto'` in any distributed mode. Please rerun your script specifying `--num_processes=1` or by launching with `python {{myscript.py}}`.
  File "training_swanlab.py", line 257, in <module>
    main()
  File "training_swanlab.py", line 250, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2275, in _inner_training_loop
    model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/accelerator.py", line 1300, in prepare
    raise ValueError(
You can't train a model that has been loaded with `device_map='auto'` in any distributed mode. Please rerun your script specifying `--num_processes=1` or by launching with `python {{myscript.py}}`.
  File "training_swanlab.py", line 257, in <module>
    main()
  File "training_swanlab.py", line 250, in main
    trainer.train()
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/transformers/trainer.py", line 2275, in _inner_training_loop
    model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)
  File "/share/home/zhangshanqi/pytorch/lib/python3.8/site-packages/accelerate/accelerator.py", line 1300, in prepare
    raise ValueError(
You can't train a model that has been loaded with `device_map='auto'` in any distributed mode. Please rerun your script specifying `--num_processes=1` or by launching with `python {{myscript.py}}`.
  File "training_swanlab.py", line 232
  File "training_swanlab.py", line 232
        optim="adamw_bnb_8bit"          # 使用8-bit优化器
optim="adamw_bnb_8bit"          # 使用8-bit优化器
        ^
^
SyntaxErrorSyntaxError: : invalid syntaxinvalid syntax

  File "training_swanlab.py", line 232
  File "training_swanlab.py", line 232
        optim="adamw_bnb_8bit"          # 使用8-bit优化器
optim="adamw_bnb_8bit"          # 使用8-bit优化器
    ^
    SyntaxError^
: SyntaxErrorinvalid syntax: 
invalid syntax
